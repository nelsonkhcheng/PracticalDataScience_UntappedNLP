{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Possibly use this if we have memory issues\n",
    "#import dask.dataframe as dd\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import accuracy\n",
    "from surprise import dump\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from utilities import data_basic_utility as databasic\n",
    "from utilities import dataframe_utility as dfutil\n",
    "import features_utility as featutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Details\n",
    "\n",
    "Working notebook of a Full Ensemble Complete Run, this time including a full NLP Regression with LightGBM\n",
    "\n",
    "Collaborative Filter models to use:\n",
    "\n",
    "* KNNWithMeans\n",
    "* BaselineOnly\n",
    "* SVDpp\n",
    "\n",
    "Content Filter models\n",
    "\n",
    "* LightGBM on all non text columns\n",
    "* LightGBM with Beer Context columns (non text)\n",
    "* SKLearn Linear Regression on all non text columns\n",
    "* LightGBM All columns including NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePrefix = \"A3_150_ensemble_v5_complete_run\"\n",
    "baseDataDir = \"C:/Development/Data/COSC2670/Assignment3/A3data/\"\n",
    "subrunDir = \"subruns/\"\n",
    "runDir = \"runs/\"\n",
    "modelsDir = \"models/\"\n",
    "forceRetrainModels = True\n",
    "\n",
    "seed = databasic.get_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = baseDataDir + 'train.tsv'\n",
    "valiFilePath = baseDataDir + 'val.tsv'\n",
    "featuresFilePath = baseDataDir + 'features.tsv'\n",
    "testFilePath = baseDataDir + 'test.tsv'\n",
    "trainFullProcessedPath = baseDataDir + 'train_features_preprocessed.csv'\n",
    "valiFullProcessedPath = baseDataDir + 'vali_features_preprocessed.csv'\n",
    "testFullProcessedPath = baseDataDir + 'test_features_preprocessed.csv'\n",
    "\n",
    "# trainFilePath = baseDataDir + 'train_200k.tsv'\n",
    "# valiFilePath = baseDataDir + 'vali_200k.tsv'\n",
    "# featuresFilePath = baseDataDir + 'features_200k.tsv'\n",
    "# testFilePath = baseDataDir + 'test_200k.tsv'\n",
    "# trainFullProcessedPath = baseDataDir + 'train_features_preprocessed_200k.csv'\n",
    "# valiFullProcessedPath = baseDataDir + 'vali_features_preprocessed_200k.csv'\n",
    "# testFullProcessedPath = baseDataDir + 'test_features_preprocessed_200k.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "useModelLbgmBeerContext = False\n",
    "useModelLbgmAllCols = False\n",
    "useModelSkLinReg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Files one by one then delete them after your done, for memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID</th>\n",
       "      <th>BeerID</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>BeerName</th>\n",
       "      <th>BeerType</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>12300</td>\n",
       "      <td>10635</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>12300</td>\n",
       "      <td>6547</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>12300</td>\n",
       "      <td>9789</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>12300</td>\n",
       "      <td>7372</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>12300</td>\n",
       "      <td>1302</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>12300</td>\n",
       "      <td>704</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>12300</td>\n",
       "      <td>1747</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>12300</td>\n",
       "      <td>9368</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>12300</td>\n",
       "      <td>2568</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>12300</td>\n",
       "      <td>6838</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowID  BeerID  ReviewerID       BeerName   BeerType  rating\n",
       "0     19   12300       10635  Rauch Ür Bock  Rauchbier     4.0\n",
       "1     21   12300        6547  Rauch Ür Bock  Rauchbier     4.5\n",
       "2     23   12300        9789  Rauch Ür Bock  Rauchbier     4.5\n",
       "3     24   12300        7372  Rauch Ür Bock  Rauchbier     5.0\n",
       "4     25   12300        1302  Rauch Ür Bock  Rauchbier     4.5\n",
       "5     26   12300         704  Rauch Ür Bock  Rauchbier     4.5\n",
       "6     29   12300        1747  Rauch Ür Bock  Rauchbier     5.0\n",
       "7     31   12300        9368  Rauch Ür Bock  Rauchbier     4.5\n",
       "8     32   12300        2568  Rauch Ür Bock  Rauchbier     4.0\n",
       "9     33   12300        6838  Rauch Ür Bock  Rauchbier     4.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(trainFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data to be just the Reviewer and the Beer(Item) and the Rating Label we want to learn.\n",
    "dfTrainFeatures = df_train.drop(['RowID','BeerName','BeerType'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Models: Train\n",
    "\n",
    "For the Collaborative Filtering Models, we only need the Training set. Train the models, then save them to file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a Surprise dataset\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "dsetTrainFeatures = Dataset.load_from_df(dfTrainFeatures[['BeerID','ReviewerID', 'rating']],reader)\n",
    "trainsetTrainFeatures = dsetTrainFeatures.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "The dump has been saved as file models/A3_150_ensemble_v5_complete_run_knnwithmeans_predictor.model\n",
      "Estimating biases using als...\n",
      "The dump has been saved as file models/A3_150_ensemble_v5_complete_run_baselineonly_predictor.model\n",
      "The dump has been saved as file models/A3_150_ensemble_v5_complete_run_svdpp_predictor.model\n"
     ]
    }
   ],
   "source": [
    "# Create each algorithm, train the model, save it to file for later, then delete the model\n",
    "\n",
    "predictorKNN = KNNWithMeans(k=160)\n",
    "featutil.trainSurpriseModel(predictorKNN, trainsetTrainFeatures, modelsDir, filePrefix, \"knnwithmeans\", forceRetrainModels)\n",
    "del predictorKNN\n",
    "\n",
    "predictorBaselineOnly = BaselineOnly(bsl_options = {'n_epochs': 5, 'reg_u': 3, 'reg_i': 16})\n",
    "featutil.trainSurpriseModel(predictorBaselineOnly, trainsetTrainFeatures, modelsDir, filePrefix, \"baselineonly\", forceRetrainModels)\n",
    "del predictorBaselineOnly\n",
    "\n",
    "predictorSVDpp = SVDpp(n_factors = 10, n_epochs=20, lr_all=0.005, reg_all=0.2)\n",
    "featutil.trainSurpriseModel(predictorSVDpp, trainsetTrainFeatures, modelsDir, filePrefix, \"svdpp\", forceRetrainModels)\n",
    "del predictorSVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the training data used for the collaborate filters\n",
    "del trainsetTrainFeatures\n",
    "del reader\n",
    "del dsetTrainFeatures\n",
    "del dfTrainFeatures\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Models: Predict On Validation Data \n",
    "\n",
    "Now we want to load the Validation set to we can predict against it and write out the subrun files, which will be used later for the Ensemble.\n",
    "\n",
    "First, do the Predictions for the Collaborative Filter models (surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation data (in full)\n",
    "df_vali = pd.read_csv(valiFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "dfValiIds = df_vali[idCols]\n",
    "dfValiFeatures = df_vali.drop(['RowID','BeerName','BeerType'],axis=1)\n",
    "\n",
    "dsetValiFeatures = Dataset.load_from_df(dfValiFeatures[['BeerID','ReviewerID', 'rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.4395\n",
      "MAE for knnwithmeans: 0.43953347322741626\n",
      "MAE:  0.4397\n",
      "MAE for baselineonly: 0.4397473132133758\n",
      "MAE:  0.4432\n",
      "MAE for svdpp: 0.4432077804052646\n"
     ]
    }
   ],
   "source": [
    "predictValiMae_KnnWithMeans = featutil.predictSurpriseModel(modelsDir, filePrefix, \"knnwithmeans\", \"val\", dsetValiFeatures, dfValiIds, subrunDir)\n",
    "predictValiMae_BaselineOnly = featutil.predictSurpriseModel(modelsDir, filePrefix, \"baselineonly\", \"val\", dsetValiFeatures, dfValiIds, subrunDir)\n",
    "predictValiMae_SVDpp = featutil.predictSurpriseModel(modelsDir, filePrefix, \"svdpp\", \"val\", dsetValiFeatures, dfValiIds, subrunDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up variables from the Predict Stage\n",
    "del df_vali\n",
    "del reader\n",
    "del dfValiIds\n",
    "del dfValiFeatures\n",
    "del dsetValiFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Filter Models, train and predict\n",
    "\n",
    "First we want to load the features and do all the data preprocessing, then we can train the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "df_train = pd.read_csv(trainFilePath,sep='\\t',\n",
    "            names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "\n",
    "# Load the validation data. When we want to do one hot encoding, we have to do it over both datasets to ensure consistency\n",
    "df_vali = pd.read_csv(valiFilePath,sep='\\t',\n",
    "            names=['RowID','BeerID','ReviewerID', 'BeerName','BeerType','rating'])\n",
    "\n",
    "# Load the validation data. When we want to do one hot encoding, we have to do it over both datasets to ensure consistency\n",
    "df_test = pd.read_csv(testFilePath,sep='\\t',\n",
    "            names=['RowID','BeerID','ReviewerID', 'BeerName','BeerType','rating'])                         \n",
    "\n",
    "# Load the features\n",
    "df_features = pd.read_csv(featuresFilePath,sep='\\t',\n",
    "    names=['RowID','BrewerID','ABV','DayofWeek','Month',\n",
    "          'DayofMonth','Year','TimeOfDay','Gender',\n",
    "          'Birthday','Text','Lemmatized','POS_Tag'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the reviewer counts to each of the data sets\n",
    "df_train = featutil.addReviewerReviewCount(df_train)\n",
    "df_train = featutil.addBeerReviewCount(df_train)\n",
    "\n",
    "df_vali = featutil.addReviewerReviewCount(df_vali)\n",
    "df_vali = featutil.addBeerReviewCount(df_vali)\n",
    "\n",
    "df_test = featutil.addReviewerReviewCount(df_test)\n",
    "df_test = featutil.addBeerReviewCount(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToUse = [\"RowID\", \"BrewerID\", \"ABV\", \"DayofWeek\", \"DayofMonth\", \"Month\", \"Year\", \"Gender\", \"TimeOfDay\", \"Birthday\"]\n",
    "\n",
    "df_train_data = df_train.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "df_vali_data = df_vali.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "df_test_data = df_test.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "\n",
    "# Remove the duplicated Row ID, also remove Beer Name at this point, we're nt using it\n",
    "df_train_data = df_train_data.drop(['RowIDFeat', \"BeerName\"],axis=1)\n",
    "df_vali_data = df_vali_data.drop(['RowIDFeat', \"BeerName\"],axis=1)\n",
    "df_test_data = df_test_data.drop(['RowIDFeat', \"BeerName\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up these dataframes now that they have been joined\n",
    "del df_train\n",
    "del df_vali\n",
    "del df_features\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237434, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Development\\COSC2670\\Assignment3\\utilities\\dataframe_utility.py:92: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  df_combined.columns = df_combined.columns.str.replace(\" \", \"\").str.replace(\"/\", \"\").str.replace(\"-\", \"\") \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1237434, 2092)\n",
      "(1237434, 2195)\n"
     ]
    }
   ],
   "source": [
    "# do the feature transformations\n",
    "df_train_data = featutil.fixNullABV(df_train_data)\n",
    "df_vali_data = featutil.fixNullABV(df_vali_data)\n",
    "df_test_data = featutil.fixNullABV(df_test_data)\n",
    "\n",
    "df_train_data, df_vali_data, df_test_data = dfutil.getDummiesForTripleSets(df_train_data, df_vali_data, df_test_data, \"BrewerID\")\n",
    "\n",
    "df_train_data, df_vali_data, df_test_data = dfutil.getDummiesForTripleSets(df_train_data, df_vali_data, df_test_data, \"BeerType\")\n",
    "\n",
    "df_train_data, df_vali_data, df_test_data = dfutil.getDummiesForTripleSets(df_train_data, df_vali_data, df_test_data, \"Gender\")\n",
    "\n",
    "df_train_data = featutil.formatDayOfWeek(df_train_data)\n",
    "df_vali_data = featutil.formatDayOfWeek(df_vali_data)\n",
    "df_test_data = featutil.formatDayOfWeek(df_test_data)\n",
    "\n",
    "df_train_data = featutil.formatMonth(df_train_data)\n",
    "df_vali_data = featutil.formatMonth(df_vali_data)\n",
    "df_test_data = featutil.formatMonth(df_test_data)\n",
    "\n",
    "df_train_data = featutil.formatTimeToSec(df_train_data)\n",
    "df_vali_data = featutil.formatTimeToSec(df_vali_data)\n",
    "df_test_data = featutil.formatTimeToSec(df_test_data)\n",
    "\n",
    "df_train_data = featutil.convertBirthdayToAge(df_train_data)\n",
    "df_vali_data = featutil.convertBirthdayToAge(df_vali_data)\n",
    "df_test_data = featutil.convertBirthdayToAge(df_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(746207, 2196)\n",
      "(243834, 2196)\n",
      "(247393, 2196)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID</th>\n",
       "      <th>BeerID</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>ReviewerReviewCount</th>\n",
       "      <th>BeerReviewCount</th>\n",
       "      <th>ABV</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>BeerType_SmokedBeer</th>\n",
       "      <th>BeerType_Tripel</th>\n",
       "      <th>BeerType_ViennaLager</th>\n",
       "      <th>BeerType_Weizenbock</th>\n",
       "      <th>BeerType_Wheatwine</th>\n",
       "      <th>BeerType_WinterWarmer</th>\n",
       "      <th>BeerType_Witbier</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>12300</td>\n",
       "      <td>10059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>12300</td>\n",
       "      <td>9761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>12300</td>\n",
       "      <td>7279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>12300</td>\n",
       "      <td>2367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>12300</td>\n",
       "      <td>2230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowID  BeerID  ReviewerID  rating  ReviewerReviewCount  BeerReviewCount  \\\n",
       "0     18   12300       10059     NaN                  165                8   \n",
       "1     20   12300        9761     NaN                  156                8   \n",
       "2     30   12300        7279     NaN                  553                8   \n",
       "3     46   12300        2367     NaN                  283                8   \n",
       "4     47   12300        2230     NaN                   35                8   \n",
       "\n",
       "   ABV  DayofWeek  DayofMonth  Month  ...  BeerType_SmokedBeer  \\\n",
       "0  7.4          7          12      6  ...                    0   \n",
       "1  7.4          6          21      5  ...                    0   \n",
       "2  7.4          2          12     10  ...                    0   \n",
       "3  5.5          3          22      7  ...                    0   \n",
       "4  5.5          2          21      7  ...                    0   \n",
       "\n",
       "   BeerType_Tripel  BeerType_ViennaLager  BeerType_Weizenbock  \\\n",
       "0                0                     0                    0   \n",
       "1                0                     0                    0   \n",
       "2                0                     0                    0   \n",
       "3                0                     0                    0   \n",
       "4                0                     0                    0   \n",
       "\n",
       "   BeerType_Wheatwine  BeerType_WinterWarmer  BeerType_Witbier  Gender_Female  \\\n",
       "0                   0                      0                 0              0   \n",
       "1                   0                      0                 0              0   \n",
       "2                   0                      0                 0              0   \n",
       "3                   0                      0                 0              0   \n",
       "4                   0                      0                 0              0   \n",
       "\n",
       "   Gender_Male  Gender_unknown  \n",
       "0            1               0  \n",
       "1            1               0  \n",
       "2            0               1  \n",
       "3            1               0  \n",
       "4            1               0  \n",
       "\n",
       "[5 rows x 2196 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train_data.shape)\n",
    "print(df_vali_data.shape)\n",
    "print(df_test_data.shape)\n",
    "df_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test data file out so we can load it back in later so as not to have to redo this step\n",
    "df_test_data.to_csv(baseDataDir + filePrefix + \"_test_cleaned.csv\", index=False)\n",
    "\n",
    "del df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_train_data.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID','rating' ])\n",
    "target_col = 'rating'\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTrainFeatures = df_train_data[feature_cols]\n",
    "dfTrainTarget = df_train_data[target_col]\n",
    "\n",
    "dfValiIds = df_vali_data[idCols]\n",
    "dfValiFeatures = df_vali_data[feature_cols]\n",
    "dfValiTarget = df_vali_data[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewerReviewCount</th>\n",
       "      <th>BeerReviewCount</th>\n",
       "      <th>ABV</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>TimeOfDay</th>\n",
       "      <th>Birthday</th>\n",
       "      <th>BrewerID_1</th>\n",
       "      <th>...</th>\n",
       "      <th>BeerType_SmokedBeer</th>\n",
       "      <th>BeerType_Tripel</th>\n",
       "      <th>BeerType_ViennaLager</th>\n",
       "      <th>BeerType_Weizenbock</th>\n",
       "      <th>BeerType_Wheatwine</th>\n",
       "      <th>BeerType_WinterWarmer</th>\n",
       "      <th>BeerType_Witbier</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>56188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>1906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>44246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>432</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>50880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>50820</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewerReviewCount  BeerReviewCount  ABV  DayofWeek  DayofMonth  Month  \\\n",
       "0                  200               23  7.4          1          23      5   \n",
       "1                   10               23  7.4          1          16      5   \n",
       "2                  164               23  7.4          7          10      4   \n",
       "3                  432               23  7.4          3          30      3   \n",
       "4                  500               23  7.4          4          24      3   \n",
       "\n",
       "   Year  TimeOfDay  Birthday  BrewerID_1  ...  BeerType_SmokedBeer  \\\n",
       "0  2011      56188         0           0  ...                    0   \n",
       "1  2011       1906         0           0  ...                    0   \n",
       "2  2011      44246         0           0  ...                    0   \n",
       "3  2011      50880         0           0  ...                    0   \n",
       "4  2011      50820        37           0  ...                    0   \n",
       "\n",
       "   BeerType_Tripel  BeerType_ViennaLager  BeerType_Weizenbock  \\\n",
       "0                0                     0                    0   \n",
       "1                0                     0                    0   \n",
       "2                0                     0                    0   \n",
       "3                0                     0                    0   \n",
       "4                0                     0                    0   \n",
       "\n",
       "   BeerType_Wheatwine  BeerType_WinterWarmer  BeerType_Witbier  Gender_Female  \\\n",
       "0                   0                      0                 0              0   \n",
       "1                   0                      0                 0              0   \n",
       "2                   0                      0                 0              0   \n",
       "3                   0                      0                 0              0   \n",
       "4                   0                      0                 0              0   \n",
       "\n",
       "   Gender_Male  Gender_unknown  \n",
       "0            1               0  \n",
       "1            1               0  \n",
       "2            0               1  \n",
       "3            1               0  \n",
       "4            1               0  \n",
       "\n",
       "[5 rows x 2192 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrainFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesBeerContext(df1):\n",
    "  consumerCols = [\"DayofWeek\", \"DayofMonth\", \"Month\", \"TimeOfDay\", \"Birthday\", \"Gender_Male\", \"Gender_Female\", \"Gender_unknown\"]\n",
    "  return dfutil.getFeaturesWithoutCols(df1, consumerCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the models, save them to file and then clear the model from memory\n",
    "if useModelLbgmBeerContext:\n",
    "    modelBeerContext = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed\n",
    "        ,learning_rate=0.010443500090385492, num_leaves = 68, max_depth = 14, n_estimators = 608\n",
    "    )  \n",
    "    dfTrainFeatures_BeerContext = getFeaturesBeerContext(dfTrainFeatures)\n",
    "    dfValiFeatures_BeerContext = getFeaturesBeerContext(dfValiFeatures)\n",
    "    featutil.trainLightGbmModel(modelBeerContext, dfTrainFeatures_BeerContext, dfTrainTarget, \n",
    "        modelsDir, filePrefix, \"lgbm_beercontext\", forceRetrainModels)\n",
    "    predictValiMae_LgbmBeerContext = featutil.predictLightGbmModel(dfValiIds, dfValiFeatures_BeerContext, dfValiTarget,\n",
    "        subrunDir, modelsDir, filePrefix, \"val\", \"lgbm_beercontext\")    \n",
    "    del dfTrainFeatures_BeerContext\n",
    "    del dfValiFeatures_BeerContext\n",
    "    del modelBeerContext\n",
    "\n",
    "if useModelLbgmAllCols:\n",
    "    modelLgbm = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed\n",
    "        ,learning_rate=0.16142127923810723, num_leaves = 127, max_depth = 18, n_estimators = 811\n",
    "    ) \n",
    "    featutil.trainLightGbmModel(modelLgbm, dfTrainFeatures, dfTrainTarget, \n",
    "        modelsDir, filePrefix, \"lgbm_allcols\", forceRetrainModels)\n",
    "    predictValiMae_LgbmAllCols = featutil.predictLightGbmModel(dfValiIds, dfValiFeatures, dfValiTarget,\n",
    "        subrunDir, modelsDir, filePrefix, \"val\", \"lgbm_allcols\")    \n",
    "    del modelLgbm\n",
    "\n",
    "if useModelSkLinReg:\n",
    "    modelLinReg = LinearRegression()\n",
    "    featutil.trainSkLinearRegModel(modelLinReg, dfTrainFeatures, dfTrainTarget, \n",
    "        modelsDir, filePrefix, \"sklinearreg\", forceRetrainModels)\n",
    "    predictValiMae_SkLinearReg = featutil.predictSkLinearRegModel(dfValiIds, dfValiFeatures, dfValiTarget,\n",
    "        subrunDir, modelsDir, filePrefix, \"val\", \"sklinearreg\")\n",
    "    del modelLinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the variables from memory\n",
    "del df_train_data\n",
    "del df_vali_data\n",
    "del dfTrainFeatures\n",
    "del dfTrainTarget\n",
    "del dfValiIds\n",
    "del dfValiFeatures\n",
    "del dfValiTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Filter Models with NLP\n",
    "\n",
    "In this version, well train the Content Filter models using NLP. Assuming that the data has been preprocessed already and saved to file via the A3_130_create_full_features_processed notebook, although later, possibly add the logic into here as part of the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID</th>\n",
       "      <th>BeerID</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>ReviewerReviewCount</th>\n",
       "      <th>BeerReviewCount</th>\n",
       "      <th>BeerType_Altbier</th>\n",
       "      <th>BeerType_AmericanAdjunctLager</th>\n",
       "      <th>BeerType_AmericanAmberRedAle</th>\n",
       "      <th>BeerType_AmericanAmberRedLager</th>\n",
       "      <th>...</th>\n",
       "      <th>Lemmatized_DocVec_190</th>\n",
       "      <th>Lemmatized_DocVec_191</th>\n",
       "      <th>Lemmatized_DocVec_192</th>\n",
       "      <th>Lemmatized_DocVec_193</th>\n",
       "      <th>Lemmatized_DocVec_194</th>\n",
       "      <th>Lemmatized_DocVec_195</th>\n",
       "      <th>Lemmatized_DocVec_196</th>\n",
       "      <th>Lemmatized_DocVec_197</th>\n",
       "      <th>Lemmatized_DocVec_198</th>\n",
       "      <th>Lemmatized_DocVec_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>12300</td>\n",
       "      <td>10635</td>\n",
       "      <td>4.0</td>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046020</td>\n",
       "      <td>-0.085923</td>\n",
       "      <td>-0.020191</td>\n",
       "      <td>0.028098</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>0.058253</td>\n",
       "      <td>-0.020965</td>\n",
       "      <td>-0.060335</td>\n",
       "      <td>-0.025998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>12300</td>\n",
       "      <td>6547</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035202</td>\n",
       "      <td>-0.071197</td>\n",
       "      <td>-0.009042</td>\n",
       "      <td>0.013252</td>\n",
       "      <td>-0.038783</td>\n",
       "      <td>-0.011112</td>\n",
       "      <td>0.017132</td>\n",
       "      <td>0.007957</td>\n",
       "      <td>-0.019318</td>\n",
       "      <td>-0.020068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>12300</td>\n",
       "      <td>9789</td>\n",
       "      <td>4.5</td>\n",
       "      <td>164</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008459</td>\n",
       "      <td>-0.038928</td>\n",
       "      <td>-0.028027</td>\n",
       "      <td>0.011146</td>\n",
       "      <td>-0.041214</td>\n",
       "      <td>-0.004981</td>\n",
       "      <td>0.029954</td>\n",
       "      <td>0.013247</td>\n",
       "      <td>-0.027631</td>\n",
       "      <td>-0.020938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>12300</td>\n",
       "      <td>7372</td>\n",
       "      <td>5.0</td>\n",
       "      <td>432</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043639</td>\n",
       "      <td>-0.069309</td>\n",
       "      <td>-0.031036</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>-0.034390</td>\n",
       "      <td>-0.008547</td>\n",
       "      <td>0.048554</td>\n",
       "      <td>0.007532</td>\n",
       "      <td>-0.044557</td>\n",
       "      <td>-0.019336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>12300</td>\n",
       "      <td>1302</td>\n",
       "      <td>4.5</td>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021395</td>\n",
       "      <td>-0.060889</td>\n",
       "      <td>-0.019478</td>\n",
       "      <td>0.016087</td>\n",
       "      <td>-0.051270</td>\n",
       "      <td>-0.012910</td>\n",
       "      <td>0.025220</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.032785</td>\n",
       "      <td>-0.020871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>12300</td>\n",
       "      <td>704</td>\n",
       "      <td>4.5</td>\n",
       "      <td>605</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025142</td>\n",
       "      <td>-0.064408</td>\n",
       "      <td>-0.026324</td>\n",
       "      <td>0.024486</td>\n",
       "      <td>-0.047075</td>\n",
       "      <td>-0.005287</td>\n",
       "      <td>0.025225</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>-0.038939</td>\n",
       "      <td>-0.025383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>12300</td>\n",
       "      <td>1747</td>\n",
       "      <td>5.0</td>\n",
       "      <td>463</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024191</td>\n",
       "      <td>-0.071046</td>\n",
       "      <td>-0.025827</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>-0.050098</td>\n",
       "      <td>-0.008236</td>\n",
       "      <td>-0.010039</td>\n",
       "      <td>-0.001957</td>\n",
       "      <td>-0.046674</td>\n",
       "      <td>-0.017337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>12300</td>\n",
       "      <td>9368</td>\n",
       "      <td>4.5</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035988</td>\n",
       "      <td>-0.069957</td>\n",
       "      <td>-0.026050</td>\n",
       "      <td>0.023177</td>\n",
       "      <td>-0.032557</td>\n",
       "      <td>-0.010953</td>\n",
       "      <td>0.026482</td>\n",
       "      <td>-0.005330</td>\n",
       "      <td>-0.052173</td>\n",
       "      <td>-0.013001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>12300</td>\n",
       "      <td>2568</td>\n",
       "      <td>4.0</td>\n",
       "      <td>221</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031430</td>\n",
       "      <td>-0.074136</td>\n",
       "      <td>-0.017969</td>\n",
       "      <td>0.024147</td>\n",
       "      <td>-0.043018</td>\n",
       "      <td>-0.012190</td>\n",
       "      <td>0.002802</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>-0.046826</td>\n",
       "      <td>-0.021015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>12300</td>\n",
       "      <td>6838</td>\n",
       "      <td>4.0</td>\n",
       "      <td>110</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038560</td>\n",
       "      <td>-0.071023</td>\n",
       "      <td>-0.026504</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>-0.042741</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.009657</td>\n",
       "      <td>-0.038897</td>\n",
       "      <td>-0.023400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 2597 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowID  BeerID  ReviewerID  rating  ReviewerReviewCount  BeerReviewCount  \\\n",
       "0     19   12300       10635     4.0                  200               23   \n",
       "1     21   12300        6547     4.5                   10               23   \n",
       "2     23   12300        9789     4.5                  164               23   \n",
       "3     24   12300        7372     5.0                  432               23   \n",
       "4     25   12300        1302     4.5                  500               23   \n",
       "5     26   12300         704     4.5                  605               23   \n",
       "6     29   12300        1747     5.0                  463               23   \n",
       "7     31   12300        9368     4.5                   49               23   \n",
       "8     32   12300        2568     4.0                  221               23   \n",
       "9     33   12300        6838     4.0                  110               23   \n",
       "\n",
       "   BeerType_Altbier  BeerType_AmericanAdjunctLager  \\\n",
       "0                 0                              0   \n",
       "1                 0                              0   \n",
       "2                 0                              0   \n",
       "3                 0                              0   \n",
       "4                 0                              0   \n",
       "5                 0                              0   \n",
       "6                 0                              0   \n",
       "7                 0                              0   \n",
       "8                 0                              0   \n",
       "9                 0                              0   \n",
       "\n",
       "   BeerType_AmericanAmberRedAle  BeerType_AmericanAmberRedLager  ...  \\\n",
       "0                             0                               0  ...   \n",
       "1                             0                               0  ...   \n",
       "2                             0                               0  ...   \n",
       "3                             0                               0  ...   \n",
       "4                             0                               0  ...   \n",
       "5                             0                               0  ...   \n",
       "6                             0                               0  ...   \n",
       "7                             0                               0  ...   \n",
       "8                             0                               0  ...   \n",
       "9                             0                               0  ...   \n",
       "\n",
       "   Lemmatized_DocVec_190  Lemmatized_DocVec_191  Lemmatized_DocVec_192  \\\n",
       "0              -0.046020              -0.085923              -0.020191   \n",
       "1              -0.035202              -0.071197              -0.009042   \n",
       "2              -0.008459              -0.038928              -0.028027   \n",
       "3              -0.043639              -0.069309              -0.031036   \n",
       "4              -0.021395              -0.060889              -0.019478   \n",
       "5              -0.025142              -0.064408              -0.026324   \n",
       "6              -0.024191              -0.071046              -0.025827   \n",
       "7              -0.035988              -0.069957              -0.026050   \n",
       "8              -0.031430              -0.074136              -0.017969   \n",
       "9              -0.038560              -0.071023              -0.026504   \n",
       "\n",
       "   Lemmatized_DocVec_193  Lemmatized_DocVec_194  Lemmatized_DocVec_195  \\\n",
       "0               0.028098               0.009554              -0.001070   \n",
       "1               0.013252              -0.038783              -0.011112   \n",
       "2               0.011146              -0.041214              -0.004981   \n",
       "3               0.009859              -0.034390              -0.008547   \n",
       "4               0.016087              -0.051270              -0.012910   \n",
       "5               0.024486              -0.047075              -0.005287   \n",
       "6               0.004000              -0.050098              -0.008236   \n",
       "7               0.023177              -0.032557              -0.010953   \n",
       "8               0.024147              -0.043018              -0.012190   \n",
       "9               0.015529              -0.042741               0.001625   \n",
       "\n",
       "   Lemmatized_DocVec_196  Lemmatized_DocVec_197  Lemmatized_DocVec_198  \\\n",
       "0               0.058253              -0.020965              -0.060335   \n",
       "1               0.017132               0.007957              -0.019318   \n",
       "2               0.029954               0.013247              -0.027631   \n",
       "3               0.048554               0.007532              -0.044557   \n",
       "4               0.025220              -0.000260              -0.032785   \n",
       "5               0.025225               0.001942              -0.038939   \n",
       "6              -0.010039              -0.001957              -0.046674   \n",
       "7               0.026482              -0.005330              -0.052173   \n",
       "8               0.002802               0.004149              -0.046826   \n",
       "9               0.001332               0.009657              -0.038897   \n",
       "\n",
       "   Lemmatized_DocVec_199  \n",
       "0              -0.025998  \n",
       "1              -0.020068  \n",
       "2              -0.020938  \n",
       "3              -0.019336  \n",
       "4              -0.020871  \n",
       "5              -0.025383  \n",
       "6              -0.017337  \n",
       "7              -0.013001  \n",
       "8              -0.021015  \n",
       "9              -0.023400  \n",
       "\n",
       "[10 rows x 2597 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "df_train = pd.read_csv(trainFullProcessedPath)\n",
    "\n",
    "df_train.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 14.4 GiB for an array with shape (2593, 746207) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16784/3602558679.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0msubsample_freq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolsample_bytree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.29392263338193186\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_alpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.891904482598078\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_lambda\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.4521335679885054\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m   )\n\u001b[1;32m---> 19\u001b[1;33m featutil.trainLightGbmModel(model_lgbm_nlp, dfTrainFeatures, dfTrainTarget, \n\u001b[0m\u001b[0;32m     20\u001b[0m     modelsDir, filePrefix, \"lgbm_allcols_inc_nlp\", forceRetrainModels)\n",
      "\u001b[1;32mc:\\Development\\COSC2670\\Assignment3\\features_utility.py\u001b[0m in \u001b[0;36mtrainLightGbmModel\u001b[1;34m(model, train_feat, train_target, modelsDir, filePrefix, modelName, forceTrain)\u001b[0m\n\u001b[0;32m    383\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mmodelPath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mFalse\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mforceTrain\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Train the model and Save the predictor model to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_feat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelsDir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfilePrefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodelName\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_predictor.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    816\u001b[0m             callbacks=None, init_model=None):\n\u001b[0;32m    817\u001b[0m         \u001b[1;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 818\u001b[1;33m         super().fit(X, y, sample_weight=sample_weight, init_score=init_score,\n\u001b[0m\u001b[0;32m    819\u001b[0m                     \u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_sample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m                     \u001b[0meval_init_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_init_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    681\u001b[0m             \u001b[0minit_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbooster_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 683\u001b[1;33m         self._Booster = train(params, train_set,\n\u001b[0m\u001b[0;32m    684\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_sets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meval_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    685\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2227\u001b[0m                 )\n\u001b[0;32m   2228\u001b[0m             \u001b[1;31m# construct booster object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2229\u001b[1;33m             \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2230\u001b[0m             \u001b[1;31m# copy the parameters from train_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2231\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1466\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1467\u001b[0m                 \u001b[1;31m# create train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1468\u001b[1;33m                 self._lazy_init(self.data, label=self.label,\n\u001b[0m\u001b[0;32m   1469\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1470\u001b[0m                                 \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1207\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1209\u001b[1;33m         data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data,\n\u001b[0m\u001b[0;32m   1210\u001b[0m                                                                                              \u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m                                                                                              \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    538\u001b[0m                              \u001b[1;34m\"Did not expect the data types in the following fields: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m                              + ', '.join(data.columns[bad_indices]))\n\u001b[1;32m--> 540\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mvalues\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   5671\u001b[0m         \"\"\"\n\u001b[0;32m   5672\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5673\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_AXIS_REVERSED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5675\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mas_array\u001b[1;34m(self, transpose, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m    870\u001b[0m                     \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    871\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 872\u001b[1;33m             \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    873\u001b[0m             \u001b[1;31m# The underlying data was copied within _interleave\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    874\u001b[0m             \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m    899\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"object\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 901\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    903\u001b[0m         \u001b[0mitemmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 14.4 GiB for an array with shape (2593, 746207) and data type float64"
     ]
    }
   ],
   "source": [
    "# Get all the columns\n",
    "col_names = df_train.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID','rating' ])\n",
    "target_col = 'rating'\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTrainIds = df_train[idCols]\n",
    "dfTrainFeatures = df_train[feature_cols]\n",
    "dfTrainTarget = df_train[target_col]\n",
    "\n",
    "# train the model\n",
    "model_lgbm_nlp = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed\n",
    "    ,learning_rate=0.09075359977364383, num_leaves = 120, max_depth = 40, n_estimators = 248, min_split_gain = 0.6310082232017945, \n",
    "    min_child_samples = 35, subsample = 0.9466694477903548, \n",
    "    subsample_freq = 0, colsample_bytree = 0.29392263338193186, reg_alpha = 0.891904482598078, reg_lambda = 0.4521335679885054\n",
    "  )\n",
    "featutil.trainLightGbmModel(model_lgbm_nlp, dfTrainFeatures, dfTrainTarget, \n",
    "    modelsDir, filePrefix, \"lgbm_allcols_inc_nlp\", forceRetrainModels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up training data from memory\n",
    "del df_train\n",
    "del dfTrainIds\n",
    "del dfTrainFeatures\n",
    "del dfTrainTarget\n",
    "\n",
    "del model_lgbm_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vali = pd.read_csv(valiFullProcessedPath)\n",
    "\n",
    "df_vali.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfValiIds = df_vali[idCols]\n",
    "dfValiFeatures = df_vali[feature_cols]\n",
    "dfValiTarget = df_vali[target_col]\n",
    "\n",
    "predictValiMae_LgbmAllColsIncNlp = featutil.predictLightGbmModel(dfValiIds, dfValiFeatures, dfValiTarget,\n",
    "    subrunDir, modelsDir, filePrefix, \"val\", \"lgbm_allcols_inc_nlp\")  \n",
    "     \n",
    "\n",
    "del df_vali\n",
    "del dfValiIds\n",
    "del dfValiFeatures\n",
    "del dfValiTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Ensemble Model\n",
    "\n",
    "Now that all the sub run files have been generated, combine all the predictions into one dataset, train a new final, ensemble model, predict on the validation data and get an MAE and save the model for use later on the Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation data (in full) again. But this time, we just want the Row and the rating\n",
    "df_vali = pd.read_csv(valiFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "\n",
    "df_ensemble_full = df_vali[[\"RowID\", \"rating\"]]      \n",
    "\n",
    "del df_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the sub runs and join them together with the ensemble data\n",
    "\n",
    "# Collaborative Filter Runs\n",
    "fileName = filePrefix + \"_\" + \"knnwithmeans\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"baselineonly\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"svdpp\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "# # Content Filter Runs\n",
    "if useModelLbgmBeerContext:\n",
    "  fileName = filePrefix + \"_\" + \"lgbm_beercontext\" + \"_val\" + \"_subrun\"\n",
    "  df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "if useModelLbgmAllCols:\n",
    "  fileName = filePrefix + \"_\" + \"lgbm_allcols\" + \"_val\" + \"_subrun\"\n",
    "  df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "if useModelSkLinReg:\n",
    "  fileName = filePrefix + \"_\" + \"sklinearreg\" + \"_val\" + \"_subrun\"\n",
    "  df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "\n",
    "# # Content Filter with NLP Runs\n",
    "fileName = filePrefix + \"_\" + \"lgbm_allcols_inc_nlp\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_ensemble_full.columns\n",
    "\n",
    "idCols = ['RowID']\n",
    "feature_cols =  col_names.drop(['RowID','rating'])\n",
    "target_col = 'rating'\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTrainIds = df_ensemble_full[idCols]\n",
    "dfTrainFeatures = df_ensemble_full[feature_cols]\n",
    "dfTrainTarget = df_ensemble_full[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing the final Ensemble prediction using Light GBM Regression, params tuned\n",
    "\n",
    "# Create the model and predict\n",
    "model = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed,\n",
    "  learning_rate=0.298864877137463, num_leaves=127, max_depth=26, n_estimators=974\n",
    ")\n",
    "model.fit(X=dfTrainFeatures, y=dfTrainTarget)\n",
    "\n",
    "# use the model to predict\n",
    "test_predicted = model.predict(dfTrainFeatures)\n",
    "dfPredicted = pd.DataFrame({\"Predict\": test_predicted})\n",
    "\n",
    "# Calc the MAE and display\n",
    "predictValiMae_Ensemble = mean_absolute_error(dfTrainTarget, test_predicted)\n",
    "print(\"Ensemble Final Average MAE (from validation data): \" + str(predictValiMae_Ensemble))\n",
    "\n",
    "# Save the model to file\n",
    "model.booster_.save_model(modelsDir + filePrefix + \"_ensemble_predictor.model\")\n",
    "\n",
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up all the variables\n",
    "del df_ensemble_full\n",
    "del dfTrainIds\n",
    "del dfTrainFeatures\n",
    "del dfTrainTarget\n",
    "del model\n",
    "del test_predicted\n",
    "del dfPredicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the Test data with Models for Subruns\n",
    "\n",
    "Now that we have the final Ensemble model, we can process the Test data. We need to load the test data, and create all the sub runs by using all the base level models to predict.\n",
    "\n",
    "First, predict using the Collaborative Filter Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation data (in full)\n",
    "df_test = pd.read_csv(testFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType'])\n",
    "\n",
    "# The test set is unlabeled, so we don't know the true ratings. Populate a rating col with zeros, as we are going\n",
    "# to predict these values\n",
    "df_test[\"rating\"] = 0\n",
    "\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "dfTestIds = df_test[idCols]\n",
    "dfTestFeatures = df_test.drop(['RowID','BeerName','BeerType'],axis=1)\n",
    "dsetTestFeatures = Dataset.load_from_df(dfTestFeatures[['BeerID','ReviewerID','rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using the Collaborative Filter Models\n",
    "featutil.predictSurpriseModel(modelsDir, filePrefix, \"knnwithmeans\", \"test\", dsetTestFeatures, dfTestIds, subrunDir)\n",
    "featutil.predictSurpriseModel(modelsDir, filePrefix, \"baselineonly\", \"test\", dsetTestFeatures, dfTestIds, subrunDir)\n",
    "featutil.predictSurpriseModel(modelsDir, filePrefix, \"svdpp\", \"test\", dsetTestFeatures, dfTestIds, subrunDir)\n",
    "\n",
    "# Ignore the displaed MAEs, since all the targets are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up variables from the Predict Stage\n",
    "del reader\n",
    "del dfTestIds\n",
    "del dfTestFeatures\n",
    "del dsetTestFeatures\n",
    "\n",
    "# Keep this, as we will use this in the next stage\n",
    "# del df_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Predict using the Content Filter Models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload that test data that was cleaned and processed previously\n",
    "df_test_data = pd.read_csv(baseDataDir + filePrefix + \"_test_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_test_data.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID', 'rating' ])\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTestIds = df_test_data[idCols]\n",
    "dfTestFeatures = df_test_data[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_test_data.columns)\n",
    "df_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is with one hot encoding, different sets of brewers or beer types between the training data (train+vali) and what is in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make predictions according to each of our Content Filter Models. Pass None for the target set, the function\n",
    "# will just skip the evaluation (calculating the MAE)\n",
    "if useModelLbgmBeerContext:\n",
    "    dfTestFeatures_BeerContext =  getFeaturesBeerContext(dfTestFeatures)\n",
    "    featutil.predictLightGbmModel(dfTestIds, dfTestFeatures_BeerContext, None,\n",
    "        subrunDir, modelsDir, filePrefix, \"test\", \"lgbm_beercontext\")    \n",
    "    del dfTestFeatures_BeerContext\n",
    "\n",
    "if useModelLbgmAllCols:\n",
    "    featutil.predictLightGbmModel(dfTestIds, dfTestFeatures, None,\n",
    "        subrunDir, modelsDir, filePrefix, \"test\", \"lgbm_allcols\") \n",
    "\n",
    "if useModelSkLinReg:\n",
    "    featutil.predictSkLinearRegModel(dfTestIds, dfTestFeatures, None,\n",
    "        subrunDir, modelsDir, filePrefix, \"test\", \"sklinearreg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_test_data\n",
    "del dfTestIds\n",
    "del dfTestFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, Predict using the Content Filter with NLP models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(testFullProcessedPath)\n",
    "\n",
    "df_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_test.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID', 'rating' ])\n",
    "\n",
    "dfTestIds = df_test[idCols]\n",
    "dfTestFeatures = df_test[feature_cols]\n",
    "\n",
    "featutil.predictLightGbmModel(dfTestIds, dfTestFeatures, None,\n",
    "    subrunDir, modelsDir, filePrefix, \"test\", \"lgbm_allcols_inc_nlp\")  \n",
    "     \n",
    "\n",
    "del dfTestIds\n",
    "del dfTestFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Ensemble Model and predict on the Test data\n",
    "\n",
    "Load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_test = df_test[[\"RowID\"]]      \n",
    "\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the sub runs and join them together with the ensemble data\n",
    "\n",
    "# Collaborative Filter Runs\n",
    "fileName = filePrefix + \"_\" + \"knnwithmeans\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"baselineonly\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"svdpp\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "# # Content Filter Runs\n",
    "if useModelLbgmBeerContext:\n",
    "  fileName = filePrefix + \"_\" + \"lgbm_beercontext\" + \"_test\" + \"_subrun\"\n",
    "  df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "if useModelLbgmAllCols:\n",
    "  fileName = filePrefix + \"_\" + \"lgbm_allcols\" + \"_test\" + \"_subrun\"\n",
    "  df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "if useModelSkLinReg:\n",
    "  fileName = filePrefix + \"_\" + \"sklinearreg\" + \"_test\" + \"_subrun\"\n",
    "  df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "\n",
    "# Content Filter Runs inc NLP doc vector cols\n",
    "fileName = filePrefix + \"_\" + \"lgbm_allcols_inc_nlp\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_ensemble_test.columns\n",
    "\n",
    "idCols = ['RowID']\n",
    "feature_cols =  col_names.drop(['RowID'])\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTestFeatures = df_ensemble_test[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ensemble model  and predict\n",
    "model = lgb.Booster(model_file=modelsDir + filePrefix + \"_ensemble_predictor.model\")\n",
    "predicted = model.predict(dfTestFeatures)\n",
    "\n",
    "dfPredictions = df_ensemble_test[idCols]\n",
    "dfPredictions[\"Score\"] = predicted\n",
    "\n",
    "# join the predictions to the ids, sort by rowid and write to out the subrun file\n",
    "finalRunFilePath = runDir + filePrefix + \"_run.tsv\"\n",
    "dfPredictions.to_csv(finalRunFilePath, sep=\"\\t\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final Report on Validation Set MAEs\")\n",
    "print(\" \")\n",
    "print(\"* KNN With Means: \" + str(predictValiMae_KnnWithMeans))\n",
    "print(\"* Baseline Only: \" + str(predictValiMae_BaselineOnly))\n",
    "print(\"* SVDpp: \" + str(predictValiMae_SVDpp))\n",
    "\n",
    "if useModelLbgmBeerContext:\n",
    "  print(\"* Lgbm Beer Context columns: \" + str(predictValiMae_LgbmBeerContext))\n",
    "\n",
    "if useModelLbgmAllCols:\n",
    "  print(\"* Lgbm All cols: \" + str(predictValiMae_LgbmAllCols))\n",
    "\n",
    "if useModelSkLinReg:\n",
    "  print(\"* Sklearn Linear Regression: \" + str(predictValiMae_SkLinearReg))\n",
    "  \n",
    "print(\"* Lgbm All cols inc NLP: \" + str(predictValiMae_LgbmAllColsIncNlp))\n",
    "print(\" \")\n",
    "print(\"Final Ensemble MAE: \" + str(predictValiMae_Ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up variables\n",
    "del df_ensemble_test\n",
    "del dfTestFeatures\n",
    "del model\n",
    "del predicted\n",
    "del dfPredictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run with the 200k data:\n",
    "\n",
    "Final Report on Validation Set MAEs\n",
    "\n",
    "* KNN With Means: 0.4378504968168548\n",
    "* Baseline Only: 0.42622980784163705\n",
    "* SVDpp: 0.4284517308694879\n",
    "* Lgbm All cols: 0.4583928664351504\n",
    "* Lgbm Beer Context columns: 0.4528618728423355\n",
    "* Sklearn Linear Regression: 0.4664260836910444\n",
    "* Lgbm All cols inc NLP: 0.4397404748454293\n",
    "\n",
    "Final Ensemble MAE: 0.2865374125139253\n",
    "\n",
    "---------\n",
    "\n",
    "## Run with all data, all models:\n",
    "\n",
    "Final Report on Validation Set MAEs\n",
    "\n",
    "* KNN With Means: 0.43953347322741626\n",
    "* Baseline Only: 0.4397473132133758\n",
    "* SVDpp: 0.44321425908767664\n",
    "* Lgbm All cols: 0.49157360211732004\n",
    "* Lgbm Beer Context columns: 0.47880436516076436\n",
    "* Sklearn Linear Regression: 0.49873941880294115\n",
    "* Lgbm All cols inc NLP: 0.4744933270571013\n",
    "\n",
    "Final Ensemble MAE: 0.41531043120736394\n",
    "\n",
    "## Run on All data, no Standard Content Filter models\n",
    "No lgbm All Cols, Beer Context or SKLearn Lin Reg\n",
    "Only 3x Collab Filter models + LGBM All cols and NLP"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c06c75df55f9518a2e4db6ce3b8ca21fb7e457d427684d07afebc061061d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
