{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "from utilities import data_basic_utility as databasic\n",
    "from utilities import dataframe_utility as dfutil\n",
    "import features_utility as featutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Details - \n",
    "\n",
    "This isn't a run file, this will load in all the data, do all the data preprocessing and write out new full files with all the data so that we can just load these in \n",
    "in the future\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePrefix = \"A3_130_create_full_featres_processed\"\n",
    "baseDataDir = \"C:/Development/Data/COSC2670/Assignment3/A3data/\"\n",
    "subrunDir = \"subruns/\"\n",
    "modelsDir = \"models/\"\n",
    "featuresDataDir = \"features/\"\n",
    "writeSubRunFile = False\n",
    "seed = databasic.get_random_seed()\n",
    "fastTextModelForceRetrain = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = baseDataDir + 'train.tsv'\n",
    "valiFilePath = baseDataDir + 'val.tsv'\n",
    "featuresFilePath = baseDataDir + 'features.tsv'\n",
    "testFilePath = baseDataDir + 'test.tsv'\n",
    "\n",
    "# trainFilePath = baseDataDir + 'train_200k.tsv'\n",
    "# valiFilePath = baseDataDir + 'vali_200k.tsv'\n",
    "# featuresFilePath = baseDataDir + 'features_200k.tsv'\n",
    "# testFilePath = baseDataDir + 'test_200k.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RowID  BeerID  ReviewerID  BeerName  BeerType  Label\n",
    "df_train = pd.read_csv(trainFilePath,sep='\\t',\n",
    "                         names=['RowID','BeerID','ReviewerID',\n",
    "                                  'BeerName','BeerType','rating'])\n",
    "df_train.head(10)\n",
    "\n",
    "df_vali = pd.read_csv(valiFilePath,sep='\\t',\n",
    "                         names=['RowID','BeerID','ReviewerID',\n",
    "                                  'BeerName','BeerType','rating'])\n",
    "df_vali.head(10)\n",
    "\n",
    "df_test = pd.read_csv(testFilePath, sep='\\t',\n",
    "                         names=['RowID','BeerID','ReviewerID',\n",
    "                                  'BeerName','BeerType','rating'])       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the Review Count columns for Reviewers and Beers to both the Train and Validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = featutil.addReviewerReviewCount(df_train)\n",
    "df_train = featutil.addBeerReviewCount(df_train)\n",
    "\n",
    "df_vali = featutil.addReviewerReviewCount(df_vali)\n",
    "df_vali = featutil.addBeerReviewCount(df_vali)\n",
    "\n",
    "df_test = featutil.addReviewerReviewCount(df_test)\n",
    "df_test = featutil.addBeerReviewCount(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)\n",
    "df_train.sort_values(\"ReviewerID\").head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode Beer Type\n",
    "df_train, df_vali, df_test = dfutil.getDummiesForTripleSets(df_train, df_vali, df_test, \"BeerType\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Beer Name to document vector columns\n",
    "df_train, df_vali, df_test, documentFilePath = featutil.formatTextColForNLP(df_train, df_vali, df_test, \"BeerName\", featuresDataDir, filePrefix, 0, 50)\n",
    "fasttext_model_bn = featutil.getFastTextLangModel(\"BeerName\", \"\",  modelsDir, filePrefix, documentFilePath, 200, fastTextModelForceRetrain)\n",
    "\n",
    "df_train_doc_vect = featutil.convertToDocVectorDataSet(df_train, \"BeerName\", fasttext_model_bn)\n",
    "df_vali_doc_vect = featutil.convertToDocVectorDataSet(df_vali, \"BeerName\", fasttext_model_bn)\n",
    "df_test_doc_vect = featutil.convertToDocVectorDataSet(df_test, \"BeerName\", fasttext_model_bn)\n",
    "\n",
    "del df_train_doc_vect[\"BeerID\"]\n",
    "del df_train_doc_vect[\"ReviewerID\"]\n",
    "del df_train_doc_vect[\"rating\"]\n",
    "del df_vali_doc_vect[\"BeerID\"]\n",
    "del df_vali_doc_vect[\"ReviewerID\"]\n",
    "del df_vali_doc_vect[\"rating\"]\n",
    "del df_test_doc_vect[\"BeerID\"]\n",
    "del df_test_doc_vect[\"ReviewerID\"]\n",
    "del df_test_doc_vect[\"rating\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)\n",
    "print(df_train_doc_vect.shape)\n",
    "print(df_vali_doc_vect.shape)\n",
    "print(df_test_doc_vect.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the Features and join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train_doc_vect[\"RowID\"]\n",
    "del df_vali_doc_vect[\"RowID\"]\n",
    "del df_test_doc_vect[\"RowID\"]\n",
    "\n",
    "df_train = pd.concat([df_train.reset_index(), df_train_doc_vect], axis=1).drop(columns=\"index\")\n",
    "df_vali = pd.concat([df_vali.reset_index(), df_vali_doc_vect], axis=1).drop(columns=\"index\")\n",
    "df_test = pd.concat([df_test.reset_index(), df_test_doc_vect], axis=1).drop(columns=\"index\")\n",
    "\n",
    "# Remove the original column from the dataset\n",
    "del df_train[\"BeerName\"]\n",
    "del df_vali[\"BeerName\"]\n",
    "del df_test[\"BeerName\"]\n",
    "\n",
    "\n",
    "del fasttext_model_bn\n",
    "\n",
    "del df_train_doc_vect\n",
    "del df_vali_doc_vect\n",
    "del df_test_doc_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RowID BrewerID ABV DayofWeek Month DayofMonth Year TimeOfDay Gender Birthday Text Lemmatized POS_Tag\n",
    "df_features = pd.read_csv(featuresFilePath,sep='\\t', names=['RowID','BrewerID','ABV','DayofWeek','Month',\n",
    "                                                                 'DayofMonth','Year','TimeOfDay','Gender',\n",
    "                                                                 'Birthday','Text','Lemmatized','POS_Tag'])\n",
    "\n",
    "\n",
    "print(df_features.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do NLP processing on Beer Name and one hot encoding on Beer Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.join(df_features, on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "df_vali = df_vali.join(df_features, on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "df_test = df_test.join(df_features, on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "\n",
    "del df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this stage, only working with Lemmatize column, remove text and postag\n",
    "del df_train[\"Text\"]\n",
    "del df_train[\"POS_Tag\"]\n",
    "del df_vali[\"Text\"]\n",
    "del df_vali[\"POS_Tag\"]\n",
    "del df_test[\"Text\"]\n",
    "del df_test[\"POS_Tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the feature transformations\n",
    "df_train = featutil.fixNullABV(df_train)\n",
    "df_vali = featutil.fixNullABV(df_vali)\n",
    "df_test = featutil.fixNullABV(df_test)\n",
    "\n",
    "df_train, df_vali, df_test = dfutil.getDummiesForTripleSets(df_train, df_vali, df_test, \"BrewerID\")\n",
    "\n",
    "df_train, df_vali, df_test = dfutil.getDummiesForTripleSets(df_train, df_vali, df_test, \"Gender\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train = featutil.formatDayOfWeek(df_train)\n",
    "df_vali = featutil.formatDayOfWeek(df_vali)\n",
    "df_test = featutil.formatDayOfWeek(df_test)\n",
    "\n",
    "df_train = featutil.formatMonth(df_train)\n",
    "df_vali = featutil.formatMonth(df_vali)\n",
    "df_test = featutil.formatMonth(df_test)\n",
    "\n",
    "df_train = featutil.formatTimeToSec(df_train)\n",
    "df_vali = featutil.formatTimeToSec(df_vali)\n",
    "df_test = featutil.formatTimeToSec(df_test)\n",
    "\n",
    "df_train = featutil.convertBirthdayToAge(df_train)\n",
    "df_vali = featutil.convertBirthdayToAge(df_vali)\n",
    "df_test = featutil.convertBirthdayToAge(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.shape)\n",
    "print(df_vali.shape)\n",
    "print(df_test.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Lemmatized Review Text to document vector columns\n",
    "df_train, df_vali, df_test, documentFilePath = featutil.formatTextColForNLP(df_train, df_vali, df_test, \"Lemmatized\", featuresDataDir, filePrefix, 0, 50)\n",
    "fasttext_model_lem = featutil.getFastTextLangModel(\"Lemmatized\", \"\",  modelsDir, filePrefix, documentFilePath, 200, fastTextModelForceRetrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_doc_vect = featutil.convertToDocVectorDataSet(df_train, \"Lemmatized\", fasttext_model_lem)\n",
    "\n",
    "del df_train_doc_vect[\"BeerID\"]\n",
    "del df_train_doc_vect[\"ReviewerID\"]\n",
    "del df_train_doc_vect[\"rating\"]\n",
    "del df_train_doc_vect[\"RowID\"]\n",
    "df_train = pd.concat([df_train.reset_index(), df_train_doc_vect], axis=1).drop(columns=\"index\")\n",
    "\n",
    "# Remove the original column from the dataset\n",
    "del df_train[\"Lemmatized\"]\n",
    "del df_train_doc_vect\n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply Standard Scaling to the set of feature columns we want to target\n",
    "# df_train = featutil.scaleMinMaxFeatureDataFrame(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_train.to_csv(baseDataDir + \"train_features_preprocessed.csv\", index=False)\n",
    "\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_vali_doc_vect = featutil.convertToDocVectorDataSet(df_vali, \"Lemmatized\", fasttext_model_lem)\n",
    "\n",
    "del df_vali_doc_vect[\"BeerID\"]\n",
    "del df_vali_doc_vect[\"ReviewerID\"]\n",
    "del df_vali_doc_vect[\"rating\"]\n",
    "del df_vali_doc_vect[\"RowID\"]\n",
    "df_vali = pd.concat([df_vali.reset_index(), df_vali_doc_vect], axis=1).drop(columns=\"index\")\n",
    "\n",
    "# Remove the original column from the dataset\n",
    "del df_vali[\"Lemmatized\"]\n",
    "del df_vali_doc_vect\n",
    "\n",
    "# # Apply Standard Scaling to the set of feature columns we want to target\n",
    "# df_vali = featutil.scaleMinMaxFeatureDataFrame(df_vali)\n",
    "\n",
    "print(df_vali.shape)\n",
    "df_vali.to_csv(baseDataDir + \"vali_features_preprocessed.csv\", index=False)\n",
    "\n",
    "del df_vali\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_test_doc_vect = featutil.convertToDocVectorDataSet(df_test, \"Lemmatized\", fasttext_model_lem)\n",
    "\n",
    "del df_test_doc_vect[\"BeerID\"]\n",
    "del df_test_doc_vect[\"ReviewerID\"]\n",
    "del df_test_doc_vect[\"rating\"]\n",
    "del df_test_doc_vect[\"RowID\"]\n",
    "df_test = pd.concat([df_test.reset_index(), df_test_doc_vect], axis=1).drop(columns=\"index\")\n",
    "\n",
    "# Remove the original column from the dataset\n",
    "del df_test[\"Lemmatized\"]\n",
    "del df_test_doc_vect\n",
    "\n",
    "# # Apply Standard Scaling to the set of feature columns we want to target\n",
    "# df_test = featutil.scaleMinMaxFeatureDataFrame(df_test)\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.to_csv(baseDataDir + \"test_features_preprocessed.csv\", index=False)\n",
    "\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # free up the memory\n",
    "del fasttext_model_lem"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c06c75df55f9518a2e4db6ce3b8ca21fb7e457d427684d07afebc061061d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
