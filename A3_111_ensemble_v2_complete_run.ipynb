{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import pickle\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise import KNNWithMeans\n",
    "from surprise import BaselineOnly\n",
    "from surprise import SVDpp\n",
    "from surprise import accuracy\n",
    "from surprise import dump\n",
    "from surprise.model_selection import train_test_split\n",
    "\n",
    "from utilities import data_basic_utility as databasic\n",
    "from utilities import dataframe_utility as dfutil\n",
    "import features_utility as featutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Details\n",
    "\n",
    "Working notebook of a Full Ensemble Run structure, with just KNNWithMeans Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePrefix = \"A3_111_ensemble_v2_complete_run\"\n",
    "baseDataDir = \"C:/Development/Data/COSC2670/Assignment3/A3data/\"\n",
    "subrunDir = \"subruns/\"\n",
    "runDir = \"runs/\"\n",
    "modelsDir = \"models/\"\n",
    "\n",
    "seed = databasic.get_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = baseDataDir + 'train.tsv'\n",
    "valiFilePath = baseDataDir + 'val.tsv'\n",
    "featuresFilePath = baseDataDir + 'features.tsv'\n",
    "testFilePath = baseDataDir + 'test.tsv'\n",
    "\n",
    "# trainFilePath = baseDataDir + 'train_200k.tsv'\n",
    "# valiFilePath = baseDataDir + 'vali_200k.tsv'\n",
    "# featuresFilePath = baseDataDir + 'features_200k.tsv'\n",
    "# testFilePath = baseDataDir + 'test_200k.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Files one by one then delete them after your done, for memory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID</th>\n",
       "      <th>BeerID</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>BeerName</th>\n",
       "      <th>BeerType</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>12300</td>\n",
       "      <td>10635</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>12300</td>\n",
       "      <td>6547</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>12300</td>\n",
       "      <td>9789</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24</td>\n",
       "      <td>12300</td>\n",
       "      <td>7372</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>12300</td>\n",
       "      <td>1302</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>12300</td>\n",
       "      <td>704</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29</td>\n",
       "      <td>12300</td>\n",
       "      <td>1747</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>12300</td>\n",
       "      <td>9368</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>32</td>\n",
       "      <td>12300</td>\n",
       "      <td>2568</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>12300</td>\n",
       "      <td>6838</td>\n",
       "      <td>Rauch Ür Bock</td>\n",
       "      <td>Rauchbier</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowID  BeerID  ReviewerID       BeerName   BeerType  rating\n",
       "0     19   12300       10635  Rauch Ür Bock  Rauchbier     4.0\n",
       "1     21   12300        6547  Rauch Ür Bock  Rauchbier     4.5\n",
       "2     23   12300        9789  Rauch Ür Bock  Rauchbier     4.5\n",
       "3     24   12300        7372  Rauch Ür Bock  Rauchbier     5.0\n",
       "4     25   12300        1302  Rauch Ür Bock  Rauchbier     4.5\n",
       "5     26   12300         704  Rauch Ür Bock  Rauchbier     4.5\n",
       "6     29   12300        1747  Rauch Ür Bock  Rauchbier     5.0\n",
       "7     31   12300        9368  Rauch Ür Bock  Rauchbier     4.5\n",
       "8     32   12300        2568  Rauch Ür Bock  Rauchbier     4.0\n",
       "9     33   12300        6838  Rauch Ür Bock  Rauchbier     4.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(trainFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the data to be just the Reviewer and the Beer(Item) and the Rating Label we want to learn.\n",
    "dfTrainFeatures = df_train.drop(['RowID','BeerName','BeerType'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Models: Train\n",
    "\n",
    "For the Collaborative Filtering Models, we only need the Training set. Train the models, then save them to file for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into a Surprise dataset\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "dsetTrainFeatures = Dataset.load_from_df(dfTrainFeatures[['BeerID','ReviewerID', 'rating']],reader)\n",
    "trainsetTrainFeatures = dsetTrainFeatures.build_full_trainset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSurpriseModel(algorithm, trainset, modelsDir, filePrefix, modelName, forceTrain=False):\n",
    "  modelSavePath = modelsDir + filePrefix + \"_\" + modelName + \"_predictor.model\"\n",
    "  modelPath = Path(modelSavePath)\n",
    "  \n",
    "  if modelPath.exists() == False or forceTrain:\n",
    "    # Train the model then Save the predictor model to file\n",
    "    model = algorithm.fit(trainset)  \n",
    "    dump.dump(modelSavePath, None, model, True)\n",
    "  else:\n",
    "    # load existing model from file\n",
    "    predictions, model = dump.load(modelsDir + filePrefix + \"_\" + modelName + \"_predictor.model\")\n",
    "\n",
    "  return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "The dump has been saved as file models/A3_111_ensemble_v2_complete_run_knnwithmeans_predictor.model\n",
      "Estimating biases using als...\n",
      "The dump has been saved as file models/A3_111_ensemble_v2_complete_run_baselineonly_predictor.model\n",
      "The dump has been saved as file models/A3_111_ensemble_v2_complete_run_svdpp_predictor.model\n"
     ]
    }
   ],
   "source": [
    "# Create each algorithm, train the model, save it to file for later, then delete the model\n",
    "\n",
    "predictorKNN = KNNWithMeans(k=160)\n",
    "trainSurpriseModel(predictorKNN, trainsetTrainFeatures, modelsDir, filePrefix, \"knnwithmeans\")\n",
    "del predictorKNN\n",
    "\n",
    "predictorBaselineOnly = BaselineOnly(bsl_options = {'n_epochs': 5, 'reg_u': 3, 'reg_i': 16})\n",
    "trainSurpriseModel(predictorBaselineOnly, trainsetTrainFeatures, modelsDir, filePrefix, \"baselineonly\")\n",
    "del predictorBaselineOnly\n",
    "\n",
    "predictorSVDpp = SVDpp(n_factors = 10, n_epochs=20, lr_all=0.005, reg_all=0.2)\n",
    "trainSurpriseModel(predictorSVDpp, trainsetTrainFeatures, modelsDir, filePrefix, \"svdpp\")\n",
    "del predictorSVDpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the training data used for the collaborate filters\n",
    "del trainsetTrainFeatures\n",
    "del reader\n",
    "del dsetTrainFeatures\n",
    "del dfTrainFeatures\n",
    "del df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative Filter Models: Predict On Validation Data \n",
    "\n",
    "Now we want to load the Validation set to we can predict against it and write out the subrun files, which will be used later for the Ensemble.\n",
    "\n",
    "First, do the Predictions for the Collaborative Filter models (surprise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation data (in full)\n",
    "df_vali = pd.read_csv(valiFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "dfValiIds = df_vali[idCols]\n",
    "dfValiFeatures = df_vali.drop(['RowID','BeerName','BeerType'],axis=1)\n",
    "\n",
    "dsetValiFeatures = Dataset.load_from_df(dfValiFeatures[['BeerID','ReviewerID', 'rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSurpriseModel(modelsDir, filePrefix, modelName, dsName, dataset, dfIds, subrunDir):\n",
    "  # Load the algorithm from the file, the predictions aren't used so that variable will be None\n",
    "  predictions, algorithm = dump.load(modelsDir + filePrefix + \"_\" + modelName + \"_predictor.model\")\n",
    "  \n",
    "  # Make Predictions using the model\n",
    "  NA,valset = train_test_split(dataset, test_size=1.0)\n",
    "  predictions = algorithm.test(valset)\n",
    "  \n",
    "  # Display the MAE\n",
    "  mae = accuracy.mae(predictions,verbose=True)\n",
    "  print(\"MAE for \" + modelName + \": \" + str(mae))\n",
    "\n",
    "  # Convert the Predictions to a dataframe so we can lookup predictions easy\n",
    "  # uid == BeerId, iid == ReviewerId, r_ui == Original Ration, est = Predicted rating\n",
    "  lstUIds = list(map(lambda x: x.uid, predictions))\n",
    "  lstIIds = list(map(lambda x: x.iid, predictions))\n",
    "  lstTrueRatings = list(map(lambda x: x.r_ui, predictions))\n",
    "  lstRatingEst = list(map(lambda x: x.est, predictions))\n",
    "  dfPredictions = pd.DataFrame({ \"uid\": lstUIds,\"iid\": lstIIds, \"r_ui\": lstTrueRatings, \"Predict\": lstRatingEst })  \n",
    "\n",
    "  # join the predictions to the ids, sort by rowid and write to out the subrun file\n",
    "  subRunFilePath = subrunDir + filePrefix + \"_\" + modelName + \"_\" + dsName + \"_subrun.csv\"\n",
    "  dfPredictions = pd.merge(dfIds, dfPredictions, how=\"inner\", left_on=[\"BeerID\", \"ReviewerID\"], right_on=[\"uid\", \"iid\"])\n",
    "  dfPredictions.sort_values(\"RowID\")[[\"RowID\", \"BeerID\", \"ReviewerID\", \"Predict\"]].to_csv(subRunFilePath, index=False)\n",
    "\n",
    "  # Clean up the variables from memory\n",
    "  del predictions\n",
    "  del algorithm\n",
    "  del valset\n",
    "  del lstUIds\n",
    "  del lstIIds\n",
    "  del lstTrueRatings\n",
    "  del lstRatingEst\n",
    "  del dfPredictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.4401\n",
      "MAE for knnwithmeans: 0.4401281860792271\n",
      "MAE:  0.4399\n",
      "MAE for baselineonly: 0.43990048246500113\n",
      "MAE:  0.4432\n",
      "MAE for svdpp: 0.4432183525372235\n"
     ]
    }
   ],
   "source": [
    "predictSurpriseModel(modelsDir, filePrefix, \"knnwithmeans\", \"val\", dsetValiFeatures, dfValiIds, subrunDir)\n",
    "predictSurpriseModel(modelsDir, filePrefix, \"baselineonly\", \"val\", dsetValiFeatures, dfValiIds, subrunDir)\n",
    "predictSurpriseModel(modelsDir, filePrefix, \"svdpp\", \"val\", dsetValiFeatures, dfValiIds, subrunDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up variables from the Predict Stage\n",
    "del df_vali\n",
    "del reader\n",
    "del dfValiIds\n",
    "del dfValiFeatures\n",
    "del dsetValiFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Filter Models, train and predict\n",
    "\n",
    "First we want to load the features and do all the data preprocessing, then we can train the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "df_train = pd.read_csv(trainFilePath,sep='\\t',\n",
    "            names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "\n",
    "# Load the validation data. When we want to do one hot encoding, we have to do it over both datasets to ensure consistency\n",
    "df_vali = pd.read_csv(valiFilePath,sep='\\t',\n",
    "            names=['RowID','BeerID','ReviewerID', 'BeerName','BeerType','rating'])\n",
    "\n",
    "# Load the validation data. When we want to do one hot encoding, we have to do it over both datasets to ensure consistency\n",
    "df_test = pd.read_csv(testFilePath,sep='\\t',\n",
    "            names=['RowID','BeerID','ReviewerID', 'BeerName','BeerType','rating'])                         \n",
    "\n",
    "# Load the features\n",
    "df_features = pd.read_csv(featuresFilePath,sep='\\t',\n",
    "    names=['RowID','BrewerID','ABV','DayofWeek','Month',\n",
    "          'DayofMonth','Year','TimeOfDay','Gender',\n",
    "          'Birthday','Text','Lemmatized','POS_Tag'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the reviewer counts to each of the data sets\n",
    "df_train = featutil.addReviewerReviewCount(df_train)\n",
    "df_train = featutil.addBeerReviewCount(df_train)\n",
    "\n",
    "df_vali = featutil.addReviewerReviewCount(df_vali)\n",
    "df_vali = featutil.addBeerReviewCount(df_vali)\n",
    "\n",
    "df_test = featutil.addReviewerReviewCount(df_test)\n",
    "df_test = featutil.addBeerReviewCount(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "colsToUse = [\"RowID\", \"BrewerID\", \"ABV\", \"DayofWeek\", \"DayofMonth\", \"Month\", \"Year\", \"Gender\", \"TimeOfDay\"]\n",
    "\n",
    "df_train_data = df_train.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "df_vali_data = df_vali.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "df_test_data = df_test.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "\n",
    "# Remove the duplicated Row ID, also remove Beer Name at this point, we're nt using it\n",
    "df_train_data = df_train_data.drop(['RowIDFeat', \"BeerName\"],axis=1)\n",
    "df_vali_data = df_vali_data.drop(['RowIDFeat', \"BeerName\"],axis=1)\n",
    "df_test_data = df_test_data.drop(['RowIDFeat', \"BeerName\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up these dataframes now that they have been joined\n",
    "del df_train\n",
    "del df_vali\n",
    "del df_features\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Development\\COSC2670\\Assignment3\\utilities\\dataframe_utility.py:92: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will*not* be treated as literal strings when regex=True.\n",
      "  df_combined.columns = df_combined.columns.str.replace(\" \", \"\").str.replace(\"/\", \"\").str.replace(\"-\", \"\") \\\n"
     ]
    }
   ],
   "source": [
    "# do the feature transformations\n",
    "df_train_data = featutil.fixNullABV(df_train_data)\n",
    "df_vali_data = featutil.fixNullABV(df_vali_data)\n",
    "df_test_data = featutil.fixNullABV(df_test_data)\n",
    "\n",
    "df_train_data, df_vali_data, df_test_data = dfutil.getDummiesForTripleSets(df_train_data, df_vali_data, df_test_data, \"BrewerID\")\n",
    "\n",
    "df_train_data, df_vali_data, df_test_data = dfutil.getDummiesForTripleSets(df_train_data, df_vali_data, df_test_data, \"BeerType\")\n",
    "\n",
    "df_train_data, df_vali_data, df_test_data = dfutil.getDummiesForTripleSets(df_train_data, df_vali_data, df_test_data, \"Gender\")\n",
    "\n",
    "df_train_data = featutil.formatDayOfWeek(df_train_data)\n",
    "df_vali_data = featutil.formatDayOfWeek(df_vali_data)\n",
    "df_test_data = featutil.formatDayOfWeek(df_test_data)\n",
    "\n",
    "df_train_data = featutil.formatMonth(df_train_data)\n",
    "df_vali_data = featutil.formatMonth(df_vali_data)\n",
    "df_test_data = featutil.formatMonth(df_test_data)\n",
    "\n",
    "df_train_data = featutil.formatTimeToSec(df_train_data)\n",
    "df_vali_data = featutil.formatTimeToSec(df_vali_data)\n",
    "df_test_data = featutil.formatTimeToSec(df_test_data)\n",
    "\n",
    "df_train_data = featutil.convertBirthdayToAge(df_train_data)\n",
    "df_vali_data = featutil.convertBirthdayToAge(df_vali_data)\n",
    "df_test_data = featutil.convertBirthdayToAge(df_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(746207, 2195)\n",
      "(243834, 2195)\n",
      "(247393, 2195)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID</th>\n",
       "      <th>BeerID</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>ReviewerReviewCount</th>\n",
       "      <th>BeerReviewCount</th>\n",
       "      <th>ABV</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>BeerType_SmokedBeer</th>\n",
       "      <th>BeerType_Tripel</th>\n",
       "      <th>BeerType_ViennaLager</th>\n",
       "      <th>BeerType_Weizenbock</th>\n",
       "      <th>BeerType_Wheatwine</th>\n",
       "      <th>BeerType_WinterWarmer</th>\n",
       "      <th>BeerType_Witbier</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>12300</td>\n",
       "      <td>10059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>12300</td>\n",
       "      <td>9761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>12300</td>\n",
       "      <td>7279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>12300</td>\n",
       "      <td>2367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>12300</td>\n",
       "      <td>2230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowID  BeerID  ReviewerID  rating  ReviewerReviewCount  BeerReviewCount  \\\n",
       "0     18   12300       10059     NaN                  165                8   \n",
       "1     20   12300        9761     NaN                  156                8   \n",
       "2     30   12300        7279     NaN                  553                8   \n",
       "3     46   12300        2367     NaN                  283                8   \n",
       "4     47   12300        2230     NaN                   35                8   \n",
       "\n",
       "   ABV  DayofWeek  DayofMonth  Month  ...  BeerType_SmokedBeer  \\\n",
       "0  7.4          7          12      6  ...                    0   \n",
       "1  7.4          6          21      5  ...                    0   \n",
       "2  7.4          2          12     10  ...                    0   \n",
       "3  5.5          3          22      7  ...                    0   \n",
       "4  5.5          2          21      7  ...                    0   \n",
       "\n",
       "   BeerType_Tripel  BeerType_ViennaLager  BeerType_Weizenbock  \\\n",
       "0                0                     0                    0   \n",
       "1                0                     0                    0   \n",
       "2                0                     0                    0   \n",
       "3                0                     0                    0   \n",
       "4                0                     0                    0   \n",
       "\n",
       "   BeerType_Wheatwine  BeerType_WinterWarmer  BeerType_Witbier  Gender_Female  \\\n",
       "0                   0                      0                 0              0   \n",
       "1                   0                      0                 0              0   \n",
       "2                   0                      0                 0              0   \n",
       "3                   0                      0                 0              0   \n",
       "4                   0                      0                 0              0   \n",
       "\n",
       "   Gender_Male  Gender_unknown  \n",
       "0            1               0  \n",
       "1            1               0  \n",
       "2            0               1  \n",
       "3            1               0  \n",
       "4            1               0  \n",
       "\n",
       "[5 rows x 2195 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train_data.shape)\n",
    "print(df_vali_data.shape)\n",
    "print(df_test_data.shape)\n",
    "df_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the test data file out so we can load it back in later so as not to have to redo this step\n",
    "df_test_data.to_csv(baseDataDir + filePrefix + \"_test_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_train_data.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID','rating' ])\n",
    "target_col = 'rating'\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTrainFeatures = df_train_data[feature_cols]\n",
    "dfTrainTarget = df_train_data[target_col]\n",
    "\n",
    "dfValiIds = df_vali_data[idCols]\n",
    "dfValiFeatures = df_vali_data[feature_cols]\n",
    "dfValiTarget = df_vali_data[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLightGbmModel(model, train_feat, train_target, \n",
    "      modelsDir, filePrefix, modelName):\n",
    "\n",
    "  # Train the model and Save the predictor model to file\n",
    "  model.fit(X=train_feat, y=train_target) \n",
    "  model.booster_.save_model(modelsDir + filePrefix + \"_\" + modelName + \"_predictor.model\")\n",
    "\n",
    "\n",
    "def trainSkLinearRegModel(model, \n",
    "      train_feat, train_target,  \n",
    "      modelsDir, filePrefix, modelName):\n",
    "  # Train the model then Save the predictor model to file\n",
    "  model.fit(train_feat, train_target) \n",
    "  pickle.dump(model, open(modelsDir + filePrefix + \"_\" + modelName + \"_predictor.model\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictLightGbmModel(vali_ids, vali_feat, vali_target, \n",
    "      subrunDir, modelsDir, filePrefix, dsName, modelName):\n",
    "\n",
    "  model = lgb.Booster(model_file=modelsDir + filePrefix + \"_\" + modelName + \"_predictor.model\")\n",
    "\n",
    "  predicted = model.predict(vali_feat)\n",
    "  dfPredicted = pd.DataFrame({\"Predict\": predicted})\n",
    "\n",
    "  # join the predictions to the ids, sort by rowid and write to out the subrun file\n",
    "  subRunFilePath = subrunDir + filePrefix + \"_\" + modelName + \"_\" + dsName + \"_subrun.csv\"\n",
    "  dfPredicted = pd.concat([vali_ids.reset_index(), dfPredicted], axis=1).drop(columns=\"index\")\n",
    "  dfPredicted.to_csv(subRunFilePath, index=False)\n",
    "\n",
    "  if vali_target is not None:      \n",
    "    mae = mean_absolute_error(vali_target, predicted)\n",
    "    print(\"MAE for \" + modelName + \": \" + str(mae))\n",
    "\n",
    "  # clean up variables in memory\n",
    "  del predicted\n",
    "  del dfPredicted\n",
    "\n",
    "\n",
    "def predictSkLinearRegModel(vali_ids, vali_feat, vali_target, \n",
    "      subrunDir, modelsDir, filePrefix, dsName, modelName):\n",
    "\n",
    "  model = pickle.load(open(modelsDir + filePrefix + \"_\" + modelName + \"_predictor.model\", 'rb'))\n",
    "\n",
    "  predicted = model.predict(vali_feat)\n",
    "  dfPredicted = pd.DataFrame({\"Predict\": predicted})\n",
    "\n",
    "  # join the predictions to the ids, sort by rowid and write to out the subrun file\n",
    "  subRunFilePath = subrunDir + filePrefix + \"_\" + modelName + \"_\" + dsName + \"_subrun.csv\"\n",
    "  dfPredicted = pd.concat([vali_ids.reset_index(), dfPredicted], axis=1).drop(columns=\"index\")\n",
    "  dfPredicted.to_csv(subRunFilePath, index=False)\n",
    "\n",
    "  # When used on the test data, we have not target/label data. This is just used for evaluation, to \n",
    "  # calculate our MAE against real labels. If none is passed in, don't do this\n",
    "  if vali_target is not None:      \n",
    "    mae = mean_absolute_error(vali_target, predicted)\n",
    "    print(\"MAE for \" + modelName + \": \" + str(mae))\n",
    "\n",
    "  # clean up variables in memory\n",
    "  del predicted\n",
    "  del dfPredicted  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReviewerReviewCount</th>\n",
       "      <th>BeerReviewCount</th>\n",
       "      <th>ABV</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>TimeOfDay</th>\n",
       "      <th>BrewerID_1</th>\n",
       "      <th>BrewerID_2</th>\n",
       "      <th>...</th>\n",
       "      <th>BeerType_SmokedBeer</th>\n",
       "      <th>BeerType_Tripel</th>\n",
       "      <th>BeerType_ViennaLager</th>\n",
       "      <th>BeerType_Weizenbock</th>\n",
       "      <th>BeerType_Wheatwine</th>\n",
       "      <th>BeerType_WinterWarmer</th>\n",
       "      <th>BeerType_Witbier</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>56188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>1906</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>164</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>44246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>432</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>50880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>23</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>2011</td>\n",
       "      <td>50820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReviewerReviewCount  BeerReviewCount  ABV  DayofWeek  DayofMonth  Month  \\\n",
       "0                  200               23  7.4          1          23      5   \n",
       "1                   10               23  7.4          1          16      5   \n",
       "2                  164               23  7.4          7          10      4   \n",
       "3                  432               23  7.4          3          30      3   \n",
       "4                  500               23  7.4          4          24      3   \n",
       "\n",
       "   Year  TimeOfDay  BrewerID_1  BrewerID_2  ...  BeerType_SmokedBeer  \\\n",
       "0  2011      56188           0           0  ...                    0   \n",
       "1  2011       1906           0           0  ...                    0   \n",
       "2  2011      44246           0           0  ...                    0   \n",
       "3  2011      50880           0           0  ...                    0   \n",
       "4  2011      50820           0           0  ...                    0   \n",
       "\n",
       "   BeerType_Tripel  BeerType_ViennaLager  BeerType_Weizenbock  \\\n",
       "0                0                     0                    0   \n",
       "1                0                     0                    0   \n",
       "2                0                     0                    0   \n",
       "3                0                     0                    0   \n",
       "4                0                     0                    0   \n",
       "\n",
       "   BeerType_Wheatwine  BeerType_WinterWarmer  BeerType_Witbier  Gender_Female  \\\n",
       "0                   0                      0                 0              0   \n",
       "1                   0                      0                 0              0   \n",
       "2                   0                      0                 0              0   \n",
       "3                   0                      0                 0              0   \n",
       "4                   0                      0                 0              0   \n",
       "\n",
       "   Gender_Male  Gender_unknown  \n",
       "0            1               0  \n",
       "1            1               0  \n",
       "2            0               1  \n",
       "3            1               0  \n",
       "4            1               0  \n",
       "\n",
       "[5 rows x 2191 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrainFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFeaturesBeerContext(df1):\n",
    "  consumerCols = [\"DayofWeek\", \"DayofMonth\", \"Month\", \"TimeOfDay\", \"Gender_Male\", \"Gender_Female\", \"Gender_unknown\"]\n",
    "  return dfutil.getFeaturesWithoutCols(df1, consumerCols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for lgbm_beercontext: 0.47784540503622086\n",
      "MAE for lgbm_consumercontext: 0.49471976836700376\n",
      "MAE for sklinearreg: 0.4987394011520422\n"
     ]
    }
   ],
   "source": [
    "# Train the models, save them to file and then clear the model from memory\n",
    "modelBeerContext = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed\n",
    "    ,learning_rate=0.010443500090385492, num_leaves = 68, max_depth = 14, n_estimators = 608\n",
    "  )  \n",
    "dfTrainFeatures_BeerContext = getFeaturesBeerContext(dfTrainFeatures)\n",
    "dfValiFeatures_BeerContext = getFeaturesBeerContext(dfValiFeatures)\n",
    "trainLightGbmModel(modelBeerContext, dfTrainFeatures_BeerContext, dfTrainTarget, \n",
    "    modelsDir, filePrefix, \"lgbm_beercontext\")\n",
    "predictLightGbmModel(dfValiIds, dfValiFeatures_BeerContext, dfValiTarget,\n",
    "    subrunDir, modelsDir, filePrefix, \"val\", \"lgbm_beercontext\")    \n",
    "del dfTrainFeatures_BeerContext\n",
    "del dfValiFeatures_BeerContext\n",
    "del modelBeerContext\n",
    "\n",
    "\n",
    "modelConsumerContext = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed\n",
    "    ,learning_rate=0.26879548049242075, num_leaves = 91, max_depth = 2, n_estimators = 384\n",
    " ) \n",
    "dfTrainFeatures_ConsumerContext = dfTrainFeatures[[\"Year\", \"ReviewerReviewCount\", \"BeerReviewCount\", \"DayofWeek\", \"DayofMonth\", \"Month\", \"TimeOfDay\", \"Gender_Male\", \"Gender_Female\", \"Gender_unknown\"]]\n",
    "dfValiFeatures_ConsumerContext = dfValiFeatures[[\"Year\", \"ReviewerReviewCount\", \"BeerReviewCount\", \"DayofWeek\", \"DayofMonth\", \"Month\", \"TimeOfDay\", \"Gender_Male\", \"Gender_Female\", \"Gender_unknown\"]]\n",
    "trainLightGbmModel(modelConsumerContext, dfTrainFeatures_ConsumerContext, dfTrainTarget, \n",
    "    modelsDir, filePrefix, \"lgbm_consumercontext\")\n",
    "predictLightGbmModel(dfValiIds, dfValiFeatures_ConsumerContext, dfValiTarget,\n",
    "    subrunDir, modelsDir, filePrefix, \"val\", \"lgbm_consumercontext\")    \n",
    "del dfTrainFeatures_ConsumerContext\n",
    "del dfValiFeatures_ConsumerContext\n",
    "del modelConsumerContext\n",
    "\n",
    "\n",
    "modelLinReg = LinearRegression()\n",
    "trainSkLinearRegModel(modelLinReg, dfTrainFeatures, dfTrainTarget, \n",
    "    modelsDir, filePrefix, \"sklinearreg\")\n",
    "predictSkLinearRegModel(dfValiIds, dfValiFeatures, dfValiTarget,\n",
    "    subrunDir, modelsDir, filePrefix, \"val\", \"sklinearreg\")\n",
    "del modelLinReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the variables from memory\n",
    "del df_train_data\n",
    "del df_vali_data\n",
    "del df_test_data\n",
    "del dfTrainFeatures\n",
    "del dfTrainTarget\n",
    "del dfValiIds\n",
    "del dfValiFeatures\n",
    "del dfValiTarget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Ensemble Model\n",
    "\n",
    "Now that all the sub run files have been generated, combine all the predictions into one dataset, train a new final, ensemble model, predict on the validation data and get an MAE and save the model for use later on the Test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation data (in full) again. But this time, we just want the Row and the rating\n",
    "df_vali = pd.read_csv(valiFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType','rating'])\n",
    "\n",
    "df_ensemble_full = df_vali[[\"RowID\", \"rating\"]]      \n",
    "\n",
    "del df_vali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the sub runs and join them together with the ensemble data\n",
    "\n",
    "# Collaborative Filter Runs\n",
    "fileName = filePrefix + \"_\" + \"knnwithmeans\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"baselineonly\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"svdpp\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "# # Content Filter Runs\n",
    "fileName = filePrefix + \"_\" + \"lgbm_beercontext\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"lgbm_consumercontext\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"sklinearreg\" + \"_val\" + \"_subrun\"\n",
    "df_ensemble_full = featutil.joinRunToEnsembleFrame(df_ensemble_full, subrunDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_ensemble_full.columns\n",
    "\n",
    "idCols = ['RowID']\n",
    "feature_cols =  col_names.drop(['RowID','rating'])\n",
    "target_col = 'rating'\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTrainIds = df_ensemble_full[idCols]\n",
    "dfTrainFeatures = df_ensemble_full[feature_cols]\n",
    "dfTrainTarget = df_ensemble_full[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Final Average MAE (from validation data): 0.41574639975141314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1857c3614f0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doing the final Ensemble prediction using Light GBM Regression, params tuned\n",
    "\n",
    "# Create the model and predict\n",
    "model = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed,\n",
    "  learning_rate=0.298864877137463, num_leaves=127, max_depth=26, n_estimators=974\n",
    ")\n",
    "model.fit(X=dfTrainFeatures, y=dfTrainTarget)\n",
    "\n",
    "# use the model to predict\n",
    "test_predicted = model.predict(dfTrainFeatures)\n",
    "dfPredicted = pd.DataFrame({\"Predict\": test_predicted})\n",
    "\n",
    "# Calc the MAE and display\n",
    "mae = mean_absolute_error(dfTrainTarget, test_predicted)\n",
    "print(\"Ensemble Final Average MAE (from validation data): \" + str(mae))\n",
    "\n",
    "# Save the model to file\n",
    "model.booster_.save_model(modelsDir + filePrefix + \"_ensemble_predictor.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up all the variables\n",
    "del df_ensemble_full\n",
    "del dfTrainIds\n",
    "del dfTrainFeatures\n",
    "del dfTrainTarget\n",
    "del model\n",
    "del test_predicted\n",
    "del dfPredicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on the Test data with Models for Subruns\n",
    "\n",
    "Now that we have the final Ensemble model, we can process the Test data. We need to load the test data, and create all the sub runs by using all the base level models to predict.\n",
    "\n",
    "First, predict using the Collaborative Filter Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the validation data (in full)\n",
    "df_test = pd.read_csv(testFilePath,sep='\\t',\n",
    "              names=['RowID','BeerID','ReviewerID','BeerName','BeerType'])\n",
    "\n",
    "# The test set is unlabeled, so we don't know the true ratings. Populate a rating col with zeros, as we are going\n",
    "# to predict these values\n",
    "df_test[\"rating\"] = 0\n",
    "\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "dfTestIds = df_test[idCols]\n",
    "dfTestFeatures = df_test.drop(['RowID','BeerName','BeerType'],axis=1)\n",
    "dsetTestFeatures = Dataset.load_from_df(dfTestFeatures[['BeerID','ReviewerID','rating']],reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3.8224\n",
      "MAE for knnwithmeans: 3.8224290696665957\n",
      "MAE:  3.8284\n",
      "MAE for baselineonly: 3.8284220621788596\n",
      "MAE:  3.8266\n",
      "MAE for svdpp: 3.8266004450114988\n"
     ]
    }
   ],
   "source": [
    "# Predict using the Collaborative Filter Models\n",
    "predictSurpriseModel(modelsDir, filePrefix, \"knnwithmeans\", \"test\", dsetTestFeatures, dfTestIds, subrunDir)\n",
    "predictSurpriseModel(modelsDir, filePrefix, \"baselineonly\", \"test\", dsetTestFeatures, dfTestIds, subrunDir)\n",
    "predictSurpriseModel(modelsDir, filePrefix, \"svdpp\", \"test\", dsetTestFeatures, dfTestIds, subrunDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up variables from the Predict Stage\n",
    "del reader\n",
    "del dfTestIds\n",
    "del dfTestFeatures\n",
    "del dsetTestFeatures\n",
    "\n",
    "# Keep this, as we will use this in the next stage\n",
    "# del df_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Predict using the Content Filter Models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload that test data that was cleaned and processed previously\n",
    "df_test_data = pd.read_csv(baseDataDir + filePrefix + \"_test_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_test_data.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID', 'rating' ])\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTestIds = df_test_data[idCols]\n",
    "dfTestFeatures = df_test_data[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RowID', 'BeerID', 'ReviewerID', 'rating', 'ReviewerReviewCount',\n",
      "       'BeerReviewCount', 'ABV', 'DayofWeek', 'DayofMonth', 'Month',\n",
      "       ...\n",
      "       'BeerType_SmokedBeer', 'BeerType_Tripel', 'BeerType_ViennaLager',\n",
      "       'BeerType_Weizenbock', 'BeerType_Wheatwine', 'BeerType_WinterWarmer',\n",
      "       'BeerType_Witbier', 'Gender_Female', 'Gender_Male', 'Gender_unknown'],\n",
      "      dtype='object', length=2195)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID</th>\n",
       "      <th>BeerID</th>\n",
       "      <th>ReviewerID</th>\n",
       "      <th>rating</th>\n",
       "      <th>ReviewerReviewCount</th>\n",
       "      <th>BeerReviewCount</th>\n",
       "      <th>ABV</th>\n",
       "      <th>DayofWeek</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>Month</th>\n",
       "      <th>...</th>\n",
       "      <th>BeerType_SmokedBeer</th>\n",
       "      <th>BeerType_Tripel</th>\n",
       "      <th>BeerType_ViennaLager</th>\n",
       "      <th>BeerType_Weizenbock</th>\n",
       "      <th>BeerType_Wheatwine</th>\n",
       "      <th>BeerType_WinterWarmer</th>\n",
       "      <th>BeerType_Witbier</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Gender_unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>12300</td>\n",
       "      <td>10059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>165</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>12300</td>\n",
       "      <td>9761</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>12300</td>\n",
       "      <td>7279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>553</td>\n",
       "      <td>8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>12300</td>\n",
       "      <td>2367</td>\n",
       "      <td>NaN</td>\n",
       "      <td>283</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>12300</td>\n",
       "      <td>2230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowID  BeerID  ReviewerID  rating  ReviewerReviewCount  BeerReviewCount  \\\n",
       "0     18   12300       10059     NaN                  165                8   \n",
       "1     20   12300        9761     NaN                  156                8   \n",
       "2     30   12300        7279     NaN                  553                8   \n",
       "3     46   12300        2367     NaN                  283                8   \n",
       "4     47   12300        2230     NaN                   35                8   \n",
       "\n",
       "   ABV  DayofWeek  DayofMonth  Month  ...  BeerType_SmokedBeer  \\\n",
       "0  7.4          7          12      6  ...                    0   \n",
       "1  7.4          6          21      5  ...                    0   \n",
       "2  7.4          2          12     10  ...                    0   \n",
       "3  5.5          3          22      7  ...                    0   \n",
       "4  5.5          2          21      7  ...                    0   \n",
       "\n",
       "   BeerType_Tripel  BeerType_ViennaLager  BeerType_Weizenbock  \\\n",
       "0                0                     0                    0   \n",
       "1                0                     0                    0   \n",
       "2                0                     0                    0   \n",
       "3                0                     0                    0   \n",
       "4                0                     0                    0   \n",
       "\n",
       "   BeerType_Wheatwine  BeerType_WinterWarmer  BeerType_Witbier  Gender_Female  \\\n",
       "0                   0                      0                 0              0   \n",
       "1                   0                      0                 0              0   \n",
       "2                   0                      0                 0              0   \n",
       "3                   0                      0                 0              0   \n",
       "4                   0                      0                 0              0   \n",
       "\n",
       "   Gender_Male  Gender_unknown  \n",
       "0            1               0  \n",
       "1            1               0  \n",
       "2            0               1  \n",
       "3            1               0  \n",
       "4            1               0  \n",
       "\n",
       "[5 rows x 2195 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test_data.columns)\n",
    "df_test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is with one hot encoding, different sets of brewers or beer types between the training data (train+vali) and what is in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can make predictions according to each of our Content Filter Models. Pass None for the target set, the function\n",
    "# will just skip the evaluation (calculating the MAE)\n",
    "dfTestFeatures_BeerContext =  getFeaturesBeerContext(dfTestFeatures)\n",
    "predictLightGbmModel(dfTestIds, dfTestFeatures_BeerContext, None,\n",
    "    subrunDir, modelsDir, filePrefix, \"test\", \"lgbm_beercontext\")    \n",
    "del dfTestFeatures_BeerContext\n",
    "\n",
    "\n",
    "dfTestFeatures_ConsumerContext = dfTestFeatures[[\"Year\", \"ReviewerReviewCount\", \"BeerReviewCount\", \"DayofWeek\", \"DayofMonth\", \"Month\", \"TimeOfDay\", \"Gender_Male\", \"Gender_Female\", \"Gender_unknown\"]]\n",
    "predictLightGbmModel(dfTestIds, dfTestFeatures_ConsumerContext, None,\n",
    "    subrunDir, modelsDir, filePrefix, \"test\", \"lgbm_consumercontext\") \n",
    "del dfTestFeatures_ConsumerContext   \n",
    "\n",
    "\n",
    "modelLinReg = LinearRegression()\n",
    "predictSkLinearRegModel(dfTestIds, dfTestFeatures, None,\n",
    "    subrunDir, modelsDir, filePrefix, \"test\", \"sklinearreg\")\n",
    "del modelLinReg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Ensemble Model and predict on the Test data\n",
    "\n",
    "Load the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_test = df_test[[\"RowID\"]]      \n",
    "\n",
    "del df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all the sub runs and join them together with the ensemble data\n",
    "\n",
    "# Collaborative Filter Runs\n",
    "fileName = filePrefix + \"_\" + \"knnwithmeans\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"baselineonly\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"svdpp\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "# # Content Filter Runs\n",
    "fileName = filePrefix + \"_\" + \"lgbm_beercontext\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"lgbm_consumercontext\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)\n",
    "\n",
    "fileName = filePrefix + \"_\" + \"sklinearreg\" + \"_test\" + \"_subrun\"\n",
    "df_ensemble_test = featutil.joinRunToEnsembleFrame(df_ensemble_test, subrunDir, fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowID</th>\n",
       "      <th>A3_111_ensemble_v2_complete_run_knnwithmeans_test_subrun</th>\n",
       "      <th>A3_111_ensemble_v2_complete_run_baselineonly_test_subrun</th>\n",
       "      <th>A3_111_ensemble_v2_complete_run_svdpp_test_subrun</th>\n",
       "      <th>A3_111_ensemble_v2_complete_run_lgbm_beercontext_test_subrun</th>\n",
       "      <th>A3_111_ensemble_v2_complete_run_lgbm_consumercontext_test_subrun</th>\n",
       "      <th>A3_111_ensemble_v2_complete_run_sklinearreg_test_subrun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4.054958</td>\n",
       "      <td>4.066056</td>\n",
       "      <td>4.057032</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.876810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>4.144754</td>\n",
       "      <td>4.092544</td>\n",
       "      <td>4.047670</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.877434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>4.328965</td>\n",
       "      <td>4.285232</td>\n",
       "      <td>4.231721</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.881769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>46</td>\n",
       "      <td>4.056218</td>\n",
       "      <td>4.114596</td>\n",
       "      <td>4.077979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.879405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47</td>\n",
       "      <td>4.357345</td>\n",
       "      <td>4.367196</td>\n",
       "      <td>4.306754</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.878607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowID  A3_111_ensemble_v2_complete_run_knnwithmeans_test_subrun  \\\n",
       "0     18                                           4.054958          \n",
       "1     20                                           4.144754          \n",
       "2     30                                           4.328965          \n",
       "3     46                                           4.056218          \n",
       "4     47                                           4.357345          \n",
       "\n",
       "   A3_111_ensemble_v2_complete_run_baselineonly_test_subrun  \\\n",
       "0                                           4.066056          \n",
       "1                                           4.092544          \n",
       "2                                           4.285232          \n",
       "3                                           4.114596          \n",
       "4                                           4.367196          \n",
       "\n",
       "   A3_111_ensemble_v2_complete_run_svdpp_test_subrun  \\\n",
       "0                                           4.057032   \n",
       "1                                           4.047670   \n",
       "2                                           4.231721   \n",
       "3                                           4.077979   \n",
       "4                                           4.306754   \n",
       "\n",
       "   A3_111_ensemble_v2_complete_run_lgbm_beercontext_test_subrun  \\\n",
       "0                                                4.0              \n",
       "1                                                4.0              \n",
       "2                                                4.0              \n",
       "3                                                4.0              \n",
       "4                                                4.0              \n",
       "\n",
       "   A3_111_ensemble_v2_complete_run_lgbm_consumercontext_test_subrun  \\\n",
       "0                                                4.0                  \n",
       "1                                                4.0                  \n",
       "2                                                4.0                  \n",
       "3                                                4.0                  \n",
       "4                                                4.0                  \n",
       "\n",
       "   A3_111_ensemble_v2_complete_run_sklinearreg_test_subrun  \n",
       "0                                           3.876810        \n",
       "1                                           3.877434        \n",
       "2                                           3.881769        \n",
       "3                                           3.879405        \n",
       "4                                           3.878607        "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ensemble_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_ensemble_test.columns\n",
    "\n",
    "idCols = ['RowID']\n",
    "feature_cols =  col_names.drop(['RowID'])\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTestFeatures = df_ensemble_test[feature_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nelso\\AppData\\Local\\Temp/ipykernel_11656/316437830.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfPredictions[\"Score\"] = predicted\n"
     ]
    }
   ],
   "source": [
    "# load the ensemble model  and predict\n",
    "model = lgb.Booster(model_file=modelsDir + filePrefix + \"_ensemble_predictor.model\")\n",
    "predicted = model.predict(dfTestFeatures)\n",
    "\n",
    "dfPredictions = df_ensemble_test[idCols]\n",
    "dfPredictions[\"Score\"] = predicted\n",
    "\n",
    "# join the predictions to the ids, sort by rowid and write to out the subrun file\n",
    "finalRunFilePath = runDir + filePrefix + \"_run.tsv\"\n",
    "dfPredictions.to_csv(finalRunFilePath, sep=\"\\t\", index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up variables\n",
    "del df_ensemble_test\n",
    "del dfTestFeatures\n",
    "del model\n",
    "del predicted\n",
    "del dfPredictions"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c06c75df55f9518a2e4db6ce3b8ca21fb7e457d427684d07afebc061061d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
