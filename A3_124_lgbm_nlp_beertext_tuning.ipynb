{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import fasttext as ft\n",
    "import optuna\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from utilities import data_basic_utility as databasic\n",
    "from utilities import dataframe_utility as dfutil\n",
    "from utilities import regex_utility as reutil\n",
    "import features_utility as featutil\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Details - Light GBM Regression NLP on Beer Text\n",
    "\n",
    "First look at NLP on the Text. Probably need to look at the Lemmatized column, possibly filter on the POS.\n",
    "But first run, will literally just feed in Lemmatized, see what happens\n",
    "\n",
    "Characteristics:\n",
    "* Light GBM Regression Algorithm\n",
    "* Start working on NLP on the Beer text columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePrefix = \"A3_124_lgbm_nlp_beertext_tuning\"\n",
    "baseDataDir = \"C:/Development/Data/COSC2670/Assignment3/A3data/\"\n",
    "subrunDir = \"subruns/\"\n",
    "featuresDataDir = \"features/\"\n",
    "modelsDir = \"models/\"\n",
    "writeSubRunFile = True\n",
    "seed = databasic.get_random_seed()\n",
    "\n",
    "# pass in an existing model file to use that was generated from another run\n",
    "modelFileToUse = \"FastText_beertext_Lemmatized_full_lang_model.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFilePath = baseDataDir + 'train.tsv'\n",
    "valiFilePath = baseDataDir + 'val.tsv'\n",
    "featuresFilePath = baseDataDir + 'features.tsv'\n",
    "testFilePath = baseDataDir + 'test.tsv'\n",
    "\n",
    "# trainFilePath = baseDataDir + 'train_200k.tsv'\n",
    "# valiFilePath = baseDataDir + 'vali_200k.tsv'\n",
    "# featuresFilePath = baseDataDir + 'features_200k.tsv'\n",
    "# testFilePath = baseDataDir + 'test_200k.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(trainFilePath, sep='\\t',\n",
    "                         names=['RowID','BeerID','ReviewerID',\n",
    "                                  'BeerName','BeerType','rating'])\n",
    "\n",
    "df_vali = pd.read_csv(valiFilePath, sep='\\t',\n",
    "                         names=['RowID','BeerID','ReviewerID',\n",
    "                                  'BeerName','BeerType','rating'])\n",
    "\n",
    "\n",
    "df_test = pd.read_csv(testFilePath, sep='\\t',\n",
    "                         names=['RowID','BeerID','ReviewerID',\n",
    "                                  'BeerName','BeerType','rating'])                                \n",
    "\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RowID BrewerID ABV DayofWeek Month DayofMonth Year TimeOfDay Gender Birthday Text Lemmatized POS_Tag\n",
    "# # df_features = pd.read_csv(baseDataDir + 'features_500k.tsv',sep='\\t', names=['RowID','BrewerID','ABV','DayofWeek','Month',\n",
    "df_features = pd.read_csv(featuresFilePath,sep='\\t', names=['RowID','BrewerID','ABV','DayofWeek','Month',\n",
    "                                                                 'DayofMonth','Year','TimeOfDay','Gender',\n",
    "                                                                 'Birthday','Text','Lemmatized','POS_Tag'])\n",
    "\n",
    "df_features.head()\n",
    "\n",
    "colsToUse = [\"Text\", \"Lemmatized\", \"POS_Tag\"]\n",
    "\n",
    "# Find the feature records that match the training and validation data and join them together\n",
    "dfFullData = df_train.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "dfFullDataVali = df_vali.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "dfFullDataTest = df_test.join(df_features[colsToUse], on=\"RowID\", how=\"inner\", rsuffix=\"Feat\")\n",
    "\n",
    "dfFullData.head()\n",
    "\n",
    "# Remove the duplicated Row ID, also remove Beer Name at this point, we're nt using it\n",
    "# df_train_data = dfFullData.drop(['RowIDFeat', \"BeerName\"],axis=1)\n",
    "# df_vali_data = dfFullDataVali.drop(['RowIDFeat', \"BeerName\"],axis=1)\n",
    "df_train_data = dfFullData.drop([\"BeerName\", \"BeerType\", \"Text\", \"POS_Tag\"],axis=1)\n",
    "df_vali_data = dfFullDataVali.drop([\"BeerName\", \"BeerType\", \"Text\", \"POS_Tag\"],axis=1)\n",
    "df_test_data = dfFullDataTest.drop([\"BeerName\", \"BeerType\", \"Text\", \"POS_Tag\"],axis=1)\n",
    "\n",
    "df_train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just look at Beer name first. Compile a full list of the beer names, save it to file with one per line. Then we can load it with fasttext and build a language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colName = \"Lemmatized\"\n",
    "df_train_data, df_vali_data, df_test_data, documentFilePath = featutil.formatTextColForNLP(df_train_data, df_vali_data, df_test_data, colName, featuresDataDir, filePrefix, 50, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most Frequent Words and Bigrams:\n",
    "[('beer', 174641), ('hop', 144586), ('head', 136003), ('taste', 115450), ('malt', 114879), ('pour', 113880), ('nice', 96037), ('flavor', 94335), ('good', 86343), ('like', 75634), ('smell', 75215), ('light', 73257), ('aroma', 72055), ('sweet', 70629), ('one', 70319), ('bit', 64462), ('bottle', 64312), ('finish', 62183), ('dark', 60571), ('glass', 59983), ('carbonation', 58731), ('color', 57863), ('well', 56893), ('little', 52933), ('mouthfeel', 47370), ('would', 45244), ('chocolate', 45155), ('lacing', 44635), ('note', 42172), ('really', 42148), ('brown', 41158), ('alcohol', 39851), ('caramel', 39761), ('body', 39751), ('great', 38695), ('much', 38127), ('get', 37967), ('white', 37964), ('medium', 37656), ('nose', 36845), ('bitter', 36704), ('citrus', 36594), ('bitterness', 36504), ('coffee', 34664), ('drink', 34411), ('leave', 33541), ('smooth', 33516), ('brew', 33311), ('hint', 32242), ('pretty', 30249)]\n",
    "\n",
    "[(('white', 'head'), 26219), (('pint', 'glass'), 15662), (('roasted', 'malt'), 13588), (('tan', 'head'), 13566), (('sweet', 'malt'), 10066), (('medium', 'bodied'), 9855), (('beer', 'pour'), 9270), (('caramel', 'malt'), 9250), (('dark', 'brown'), 9016), (('bottle', 'pour'), 8550), (('dark', 'fruit'), 8504), (('oz', 'bottle'), 8069), (('medium', 'body'), 8026), (('hop', 'flavor'), 8002), (('pour', 'dark'), 7601), (('hop', 'bitterness'), 7299), (('amber', 'color'), 7210), (('12', 'oz'), 6761), (('dark', 'chocolate'), 6717), (('pale', 'ale'), 6651), (('little', 'bit'), 6595), (('taste', 'like'), 6426), (('offwhite', 'head'), 6300), (('citrus', 'hop'), 6226), (('head', 'leave'), 6019), (('smell', 'like'), 6018), (('lacing', 'smell'), 5995), (('good', 'beer'), 5940), (('pour', 'clear'), 5806), (('12oz', 'bottle'), 5711), (('brown', 'sugar'), 5456), (('pretty', 'good'), 5415), (('head', 'smell'), 5367), (('easy', 'drink'), 5357), (('well', 'balanced'), 5290), (('floral', 'hop'), 5268), (('finger', 'head'), 5252), (('glass', 'pour'), 5189), (('hop', 'aroma'), 5162), (('malt', 'flavor'), 5054), (('sierra', 'nevada'), 4776), (('dry', 'finish'), 4737), (('pour', 'deep'), 4656), (('full', 'bodied'), 4652), (('brown', 'head'), 4525), (('golden', 'color'), 4509), (('brown', 'color'), 4498), (('pour', 'nice'), 4490), (('hop', 'taste'), 4427), (('head', 'aroma'), 4384)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now train a Fast Text language model. Check to see if there is a saved model to use, else train a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model = featutil.getFastTextLangModel(colName, modelFileToUse,  modelsDir, filePrefix, documentFilePath, 200, True)\n",
    "\n",
    "print(fasttext_model.words[0:50])\n",
    "\n",
    "# examine some of the word vectors\n",
    "# print(fasttext_model.get_word_vector(\"stout\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_data = df_train\n",
    "# df_vali_data = df_vali\n",
    "# df_test_data = df_test\n",
    "\n",
    "print(df_train_data.shape)\n",
    "print(df_vali_data.shape)\n",
    "\n",
    "df_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe that just the Ids, rating and document vectors, but at columns\n",
    "df_train_data = featutil.convertToDocVectorDataSet(df_train_data, colName, fasttext_model)\n",
    "df_vali_data = featutil.convertToDocVectorDataSet(df_vali_data, colName, fasttext_model)\n",
    "df_test_data = featutil.convertToDocVectorDataSet(df_test_data, colName, fasttext_model)\n",
    "\n",
    "df_vali_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write test data to file, when we do a complete run. Otherwise, just drop the test data out of memory\n",
    "del df_test\n",
    "del df_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_train_data.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID','rating' ])\n",
    "target_col = 'rating'\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTrainIds = df_train_data[idCols]\n",
    "dfTrainFeatures = df_train_data[feature_cols]\n",
    "dfTrainTarget = df_train_data[target_col]\n",
    "\n",
    "dfValiIds = df_vali_data[idCols]\n",
    "dfValiFeatures = df_vali_data[feature_cols]\n",
    "dfValiTarget = df_vali_data[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfValiIds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTrainFeatures.shape)\n",
    "dfTrainFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "  # Create the Light GBM Regression model and train\n",
    "  model = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed\n",
    "    ,learning_rate=trial.suggest_float(\"learning_rate\", 0.005, 0.3)\n",
    "    ,num_leaves=trial.suggest_int(\"num_leaves\", 2, 127)\n",
    "    ,max_depth=trial.suggest_int(\"max_depth\", 2, 30)\n",
    "    ,n_estimators=trial.suggest_int(\"n_estimators \", 50, 1000)\n",
    "    # ,min_split_gain=trial.suggest_float(\"min_split_gain\", 0.001, 1.0)\n",
    "    # ,min_child_samples=trial.suggest_int(\"min_child_samples\", 1, 100)  \n",
    "    # #,min_child_weight =trial.suggest_float(\"min_child_weight\", 0.0001, 0.1) \n",
    "    # ,subsample =trial.suggest_float(\"subsample\", 0.1, 1.0) \n",
    "    # ,subsample_freq =trial.suggest_int(\"subsample_freq\", 0, 15)\n",
    "    # ,colsample_bytree =trial.suggest_float(\"colsample_bytree\", 0.1, 1.0) \n",
    "    # ,reg_alpha =trial.suggest_float(\"reg_alpha\", 0.1, 1.0) \n",
    "    # ,reg_lambda =trial.suggest_float(\"reg_lambda\", 0.1, 1.0)      \n",
    "  )\n",
    "\n",
    "  model.fit(X=dfTrainFeatures, y=dfTrainTarget)\n",
    "\n",
    "  # Use the model to predict against our validation data\n",
    "  test_predicted = model.predict(dfValiFeatures)  \n",
    "\n",
    "  mae = mean_absolute_error(dfValiTarget, test_predicted)\n",
    "\n",
    "  return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=25)\n",
    "\n",
    "print(\"\\n---------\")\n",
    "print(\"Study Complete\")\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(\"Best Rank Score: \" + str(study.best_value))\n",
    "print(\"-------\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c06c75df55f9518a2e4db6ce3b8ca21fb7e457d427684d07afebc061061d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
