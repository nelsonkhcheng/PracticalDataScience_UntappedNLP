{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "# import pandas as pd\n",
    "import dask.dataframe as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from utilities import data_basic_utility as databasic\n",
    "from utilities import dataframe_utility as dfutil\n",
    "import features_utility as featutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Details - Light GBM Regression All cols inc nlp\n",
    "\n",
    "This is a Candidate for being used in an Ensemble 2. \n",
    "Characteristicts:\n",
    "* Light GBM Regression Algorithm\n",
    "* All columns, including Review Counts and NLP doc vecs\n",
    "* Uses the full files outputted from A3_130\n",
    "* Todo: use optimised parameters for Light GBM Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePrefix = \"A3_140_lgbm_regression_inc_nlp\"\n",
    "baseDataDir = \"C:/Development/Data/COSC2670/Assignment3/A3data/\"\n",
    "subrunDir = \"subruns/\"\n",
    "writeSubRunFile = True\n",
    "seed = databasic.get_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trainFilePath = baseDataDir + 'train_features_preprocessed.csv'\n",
    "valiFilePath = baseDataDir + 'vali_features_preprocessed.csv'\n",
    "testFilePath = baseDataDir + 'test_features_preprocessed.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RowID  BeerID  ReviewerID  BeerName  BeerType  Label\n",
    "# df_train = pd.read_csv(baseDataDir + 'train_500k.tsv',sep='\\t',\n",
    "df_train = pd.read_csv(trainFilePath)\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df_vali = pd.read_csv(baseDataDir + 'vali_500k.tsv',sep='\\t',\n",
    "df_vali = pd.read_csv(valiFilePath)\n",
    "df_vali.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del df_train[\"BeerName\"]\n",
    "del df_train[\"Lemmatized\"]\n",
    "del df_vali[\"BeerName\"]\n",
    "del df_vali[\"Lemmatized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the columns\n",
    "col_names = df_train.columns\n",
    "\n",
    "idCols = ['RowID','BeerID','ReviewerID']\n",
    "feature_cols =  col_names.drop(['RowID','BeerID','ReviewerID','rating' ])\n",
    "target_col = 'rating'\n",
    "\n",
    "# Create the sub data sets of the features and the target\n",
    "dfTrainIds = df_train[idCols]\n",
    "dfTrainFeatures = df_train[feature_cols]\n",
    "dfTrainTarget = df_train[target_col]\n",
    "\n",
    "dfValiIds = df_vali[idCols]\n",
    "dfValiFeatures = df_vali[feature_cols]\n",
    "dfValiTarget = df_vali[target_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTrainFeatures.shape)\n",
    "dfTrainFeatures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "  # Create the Light GBM Regression model and train\n",
    "  model = lgb.LGBMRegressor(objective=\"regression_l1\", metric=\"mae\", random_state=seed\n",
    "    ,learning_rate=trial.suggest_float(\"learning_rate\", 0.005, 0.3)\n",
    "    ,num_leaves=trial.suggest_int(\"num_leaves\", 60, 127)\n",
    "    ,max_depth=trial.suggest_int(\"max_depth\", 10, 30)\n",
    "    ,n_estimators=trial.suggest_int(\"n_estimators \", 200, 1000)\n",
    "    # ,min_split_gain=trial.suggest_float(\"min_split_gain\", 0.001, 1.0)\n",
    "    # ,min_child_samples=trial.suggest_int(\"min_child_samples\", 1, 100)  \n",
    "    # #,min_child_weight =trial.suggest_float(\"min_child_weight\", 0.0001, 0.1) \n",
    "    # ,subsample =trial.suggest_float(\"subsample\", 0.1, 1.0) \n",
    "    # ,subsample_freq =trial.suggest_int(\"subsample_freq\", 0, 15)\n",
    "    # ,colsample_bytree =trial.suggest_float(\"colsample_bytree\", 0.1, 1.0) \n",
    "    # ,reg_alpha =trial.suggest_float(\"reg_alpha\", 0.1, 1.0) \n",
    "    # ,reg_lambda =trial.suggest_float(\"reg_lambda\", 0.1, 1.0)      \n",
    "  )\n",
    "\n",
    "  model.fit(X=dfTrainFeatures, y=dfTrainTarget)\n",
    "\n",
    "  # Use the model to predict against our validation data\n",
    "  test_predicted = model.predict(dfValiFeatures)  \n",
    "\n",
    "  mae = mean_absolute_error(dfValiTarget, test_predicted)\n",
    "\n",
    "  return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "print(\"\\n---------\")\n",
    "print(\"Study Complete\")\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(study.best_params)\n",
    "print(\"Best Rank Score: \" + str(study.best_value))\n",
    "print(\"-------\")\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a1c06c75df55f9518a2e4db6ce3b8ca21fb7e457d427684d07afebc061061d6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
